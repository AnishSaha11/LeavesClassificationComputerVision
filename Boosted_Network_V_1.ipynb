{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pickle\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images first\n",
    "numImages = len(glob.glob('./images/*jpg'))\n",
    "images = [None for i in xrange(numImages)]\n",
    "for fileName in glob.glob('./images/*jpg'):\n",
    "    fileNum = int(fileName[9:][:-4])\n",
    "    images[fileNum-1] = np.array(cv2.imread(fileName))\n",
    "images = np.array(images)\n",
    "\n",
    "# Load csv data next\n",
    "train_data = pd.read_csv('data/train.csv').drop(['species'], axis=1).values\n",
    "train_labels = pd.read_csv('data/train.csv')['species'].values\n",
    "labels=train_labels.tolist()\n",
    "train_images = [images[int(data[0]-1)] for data in train_data]\n",
    "train_ids = [data[0] for data in train_data]\n",
    "train_data = np.delete(train_data, 0, 1)\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('data/test.csv').values\n",
    "test_images = [images[int(data[0]-1)] for data in test_data]\n",
    "test_ids = [data[0] for data in test_data]\n",
    "test_data = np.delete(test_data, 0, 1)\n",
    "\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MiniBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN train data\n",
    "def img_norm(img):\n",
    "    t= 2 * (np.float32(img) / 255 - 0.5) # normalize img pixels to [-1, 1]\n",
    "    return t\n",
    "def minibatchData(data,labels_encoded,img_size,channel_num=3,batch_num=30):\n",
    "    images=[]\n",
    "    for img in data:\n",
    "        images.append(np.transpose(img_norm(cv2.resize(img,img_size)),[2,0,1]))\n",
    "    \n",
    "    \n",
    "    if batch_num > 1:\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        print(len(images))\n",
    "        print(batch_num)\n",
    "        \n",
    "        for i in range(int(len(images) / batch_num)):\n",
    "            minibatch_d = images[i*batch_num: (i+1)*batch_num]\n",
    "            minibatch_d = np.reshape(minibatch_d, (batch_num, channel_num,img_size[0],img_size[1]))\n",
    "            batch_data.append(torch.from_numpy(minibatch_d))\n",
    "            if labels_encoded is not None:\n",
    "                minibatch_l = labels_encoded[i*batch_num: (i+1)*batch_num]\n",
    "                batch_labels.append(torch.LongTensor(minibatch_l))\n",
    "            else:\n",
    "                minibatch_l = np.zeros(batch_num)\n",
    "                batch_labels.append(torch.LongTensor(minibatch_l))\n",
    "        #data, labels = batch_data, batch_labels \n",
    "        \n",
    "    return zip(batch_data, batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le= preprocessing.LabelEncoder()\n",
    "#encode train labels\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded=le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "img_size=(224,224)\n",
    "cnn_train_data = list(minibatchData(train_images,train_labels_encoded,img_size))\n",
    "#plt.imshow(cnn_train_data[0][0][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a6fa15850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_test_data = list(minibatchData(test_images,None,img_size,batch_num=2))\n",
    "#print cnn_train_data.size\n",
    "plt.imshow(cnn_test_data[0][0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tuned alexnet instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='tunedAlex.sav'\n",
    "model_ft = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 99)\n"
     ]
    }
   ],
   "source": [
    "probs_cnn_train=np.empty([0,99])\n",
    "#sm = torch.nn.Softmax()\n",
    "for data in cnn_train_data:\n",
    "    images,labels=data\n",
    "    probs_cnn_train=np.append(probs_cnn_train,(model_ft(images)).data.numpy(),axis=0)\n",
    "print probs_cnn_train.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 99)\n"
     ]
    }
   ],
   "source": [
    "probs_cnn_test=np.empty([0,99])\n",
    "for data in cnn_test_data:\n",
    "    images, labels = data\n",
    "    probs_cnn_test=np.append(probs_cnn_test,(model_ft(images)).data.numpy(),axis=0)\n",
    "    #outputs=np.append(outputs,net(images).data.numpy(),axis=0)\n",
    "    #print probs\n",
    "    \n",
    "\n",
    "print probs_cnn_test.shape\n",
    "\n",
    "#sm = torch.nn.Softmax()\n",
    "#probabilities = sm(output) \n",
    "#print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the 3 histograms\n",
    "train_margin_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'margin1':'margin64']).values\n",
    "train_shape_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'shape1':'shape64']).values\n",
    "train_texture_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'texture1':'texture64']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_margin_data=((pd.read_csv('data/test.csv')).loc[:,'margin1':'margin64']).values\n",
    "test_shape_data=((pd.read_csv('data/test.csv')).loc[:,'shape1':'shape64']).values\n",
    "test_texture_data=((pd.read_csv('data/test.csv')).loc[:,'texture1':'texture64']).values\n",
    "\n",
    "#print train_margin_data.head()\n",
    "#print train_shape_data.head()\n",
    "#print train_texture_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(images, dense=False):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    des_per_Img = np.array([sift.detectAndCompute(img,None)[1] for img in images])\n",
    "    return des_per_Img\n",
    "        \n",
    "def get_clusters(descriptors, vocabSize):\n",
    "    des_list = np.concatenate(descriptors)\n",
    "\n",
    "    kmeans = MiniBatchKMeans(vocabSize, batch_size=100)\n",
    "    kmeans.fit(np.array(des_list))\n",
    "    \n",
    "    return kmeans\n",
    "\n",
    "def get_vocabulary(descriptors, clusters, vocabSize):\n",
    "    return np.array([normalize(np.histogram(clusters.predict(dscrs), bins=range(vocabSize))[0].reshape(1,-1)).ravel() for dscrs in descriptors])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors computed in 133.268115 seconds\n"
     ]
    }
   ],
   "source": [
    "des_start_time =time.time()\n",
    "des_list_train = get_descriptor(train_images)\n",
    "\n",
    "des_list_test = get_descriptor(test_images)\n",
    "des_end_time =time.time()\n",
    "print \"Descriptors computed in {:2f} seconds\".format(des_end_time-des_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering completed in 2.823910 seconds\n"
     ]
    }
   ],
   "source": [
    "clustering_start_time=time.time()\n",
    "clusters = get_clusters(des_list_train,150)\n",
    "clustering_end_time=time.time()\n",
    "print \"Clustering completed in {:2f} seconds\".format(clustering_end_time-clustering_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 149)\n"
     ]
    }
   ],
   "source": [
    "vocab_train = get_vocabulary(des_list_train,clusters,150)\n",
    "vocab_test = get_vocabulary(des_list_test,clusters,150)\n",
    "\n",
    "print vocab_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.utils import np_utils\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.add(Dense(512,activation='relu'))\n",
    "deep_model.add(Dropout(0.5))\n",
    "deep_model.add(Dense(1024,activation='relu'))\n",
    "deep_model.add(Dropout(0.5))\n",
    "deep_model.add(Dense(2048,activation='relu'))\n",
    "deep_model.add(Dropout(0.5))\n",
    "deep_model.add(Dense(256,activation='relu'))\n",
    "deep_model.add(Dropout(0.5))\n",
    "deep_model.add(Dense(99,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss='categorical_crossentropy',optimizer='adam',metric=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 440)\n"
     ]
    }
   ],
   "source": [
    "deep_input=np.array(np.append(train_margin_data,train_texture_data,axis=1))\n",
    "deep_input=np.array(np.append(deep_input,train_shape_data,axis=1))\n",
    "deep_input=np.array(np.append(deep_input,vocab_train,axis=1))\n",
    "deep_input=np.array(np.append(deep_input,probs_cnn_train,axis=1))\n",
    "Y_labels = np_utils.to_categorical(train_labels_encoded,99)\n",
    "print deep_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "990/990 [==============================] - 7s 7ms/step - loss: 5.0132\n",
      "Epoch 2/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 4.4938\n",
      "Epoch 3/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 4.1971\n",
      "Epoch 4/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 3.8280\n",
      "Epoch 5/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 3.3897\n",
      "Epoch 6/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 3.1198\n",
      "Epoch 7/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 2.8209\n",
      "Epoch 8/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 2.4798\n",
      "Epoch 9/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 2.2941\n",
      "Epoch 10/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 2.0476\n",
      "Epoch 11/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 2.0619\n",
      "Epoch 12/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.8008\n",
      "Epoch 13/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.7266\n",
      "Epoch 14/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.6797\n",
      "Epoch 15/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.5186\n",
      "Epoch 16/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.4524\n",
      "Epoch 17/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.3863\n",
      "Epoch 18/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.3548\n",
      "Epoch 19/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.3630\n",
      "Epoch 20/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.2674\n",
      "Epoch 21/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.1791\n",
      "Epoch 22/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.2293\n",
      "Epoch 23/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.2001\n",
      "Epoch 24/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.1524\n",
      "Epoch 25/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0505\n",
      "Epoch 26/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0277\n",
      "Epoch 27/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0265\n",
      "Epoch 28/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0891\n",
      "Epoch 29/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0433\n",
      "Epoch 30/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0067\n",
      "Epoch 31/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9494\n",
      "Epoch 32/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9382\n",
      "Epoch 33/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9615\n",
      "Epoch 34/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9503\n",
      "Epoch 35/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8750\n",
      "Epoch 36/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8721\n",
      "Epoch 37/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9420\n",
      "Epoch 38/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9126\n",
      "Epoch 39/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9401\n",
      "Epoch 40/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8402\n",
      "Epoch 41/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8335\n",
      "Epoch 42/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9029\n",
      "Epoch 43/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7780\n",
      "Epoch 44/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7400\n",
      "Epoch 45/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7702\n",
      "Epoch 46/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9359\n",
      "Epoch 47/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8909\n",
      "Epoch 48/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9364\n",
      "Epoch 49/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.7462\n",
      "Epoch 50/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7657\n",
      "Epoch 51/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8470\n",
      "Epoch 52/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8412\n",
      "Epoch 53/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7707\n",
      "Epoch 54/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7737\n",
      "Epoch 55/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8373\n",
      "Epoch 56/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7215\n",
      "Epoch 57/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6846\n",
      "Epoch 58/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7394\n",
      "Epoch 59/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6825\n",
      "Epoch 60/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7371\n",
      "Epoch 61/200\n",
      "990/990 [==============================] - 5s 6ms/step - loss: 0.7223\n",
      "Epoch 62/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8368\n",
      "Epoch 63/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6080\n",
      "Epoch 64/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7400\n",
      "Epoch 65/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8145\n",
      "Epoch 66/200\n",
      "990/990 [==============================] - 5s 6ms/step - loss: 0.7164\n",
      "Epoch 67/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7668\n",
      "Epoch 68/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6518\n",
      "Epoch 69/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.5969\n",
      "Epoch 70/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7865\n",
      "Epoch 71/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7160\n",
      "Epoch 72/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7297\n",
      "Epoch 73/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8524\n",
      "Epoch 74/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7621\n",
      "Epoch 75/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6912\n",
      "Epoch 76/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.5994\n",
      "Epoch 77/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6932\n",
      "Epoch 78/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.6699\n",
      "Epoch 79/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.5921\n",
      "Epoch 80/200\n",
      "990/990 [==============================] - 5s 6ms/step - loss: 0.6830\n",
      "Epoch 81/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6969\n",
      "Epoch 82/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.5944\n",
      "Epoch 83/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7244\n",
      "Epoch 84/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6676\n",
      "Epoch 85/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6462\n",
      "Epoch 86/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6707\n",
      "Epoch 87/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6950\n",
      "Epoch 88/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6968\n",
      "Epoch 89/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7825\n",
      "Epoch 90/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6399\n",
      "Epoch 91/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7833\n",
      "Epoch 92/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6109\n",
      "Epoch 93/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7790\n",
      "Epoch 94/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7224\n",
      "Epoch 95/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8457\n",
      "Epoch 96/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7307\n",
      "Epoch 97/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6598\n",
      "Epoch 98/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6194\n",
      "Epoch 99/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7659\n",
      "Epoch 100/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7638\n",
      "Epoch 101/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7342\n",
      "Epoch 102/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8171\n",
      "Epoch 103/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8753\n",
      "Epoch 104/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7949\n",
      "Epoch 105/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7182\n",
      "Epoch 106/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8099\n",
      "Epoch 107/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9490\n",
      "Epoch 108/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.7441\n",
      "Epoch 109/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7033\n",
      "Epoch 110/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6198\n",
      "Epoch 111/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.5655\n",
      "Epoch 112/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7109\n",
      "Epoch 113/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7854\n",
      "Epoch 114/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7433\n",
      "Epoch 115/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6890\n",
      "Epoch 116/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8045\n",
      "Epoch 117/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8190\n",
      "Epoch 118/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7824\n",
      "Epoch 119/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9771\n",
      "Epoch 120/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7648\n",
      "Epoch 121/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7779\n",
      "Epoch 122/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7929\n",
      "Epoch 123/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8526\n",
      "Epoch 124/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9445\n",
      "Epoch 125/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8623\n",
      "Epoch 126/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7962\n",
      "Epoch 127/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9951\n",
      "Epoch 128/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.9746\n",
      "Epoch 129/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9947\n",
      "Epoch 130/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9921\n",
      "Epoch 131/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7746\n",
      "Epoch 132/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8293\n",
      "Epoch 133/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9628\n",
      "Epoch 134/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6577\n",
      "Epoch 135/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6486\n",
      "Epoch 136/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8512\n",
      "Epoch 137/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9322\n",
      "Epoch 138/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8422\n",
      "Epoch 139/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7190\n",
      "Epoch 140/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7974\n",
      "Epoch 141/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6967\n",
      "Epoch 142/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7996\n",
      "Epoch 143/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7642\n",
      "Epoch 144/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7087\n",
      "Epoch 145/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.5696\n",
      "Epoch 146/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6516\n",
      "Epoch 147/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8987\n",
      "Epoch 148/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9286\n",
      "Epoch 149/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9018\n",
      "Epoch 150/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.9045\n",
      "Epoch 151/200\n",
      "990/990 [==============================] - 6s 6ms/step - loss: 0.8736\n",
      "Epoch 152/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8183\n",
      "Epoch 153/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0480\n",
      "Epoch 154/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8788\n",
      "Epoch 155/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8731\n",
      "Epoch 156/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8319\n",
      "Epoch 157/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7602\n",
      "Epoch 158/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7648\n",
      "Epoch 159/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6677\n",
      "Epoch 160/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8496\n",
      "Epoch 161/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8257\n",
      "Epoch 162/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7376\n",
      "Epoch 163/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8992\n",
      "Epoch 164/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8389\n",
      "Epoch 165/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8882\n",
      "Epoch 166/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6077\n",
      "Epoch 167/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9024\n",
      "Epoch 168/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8684\n",
      "Epoch 169/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9633\n",
      "Epoch 170/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9789\n",
      "Epoch 171/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7221\n",
      "Epoch 172/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8579\n",
      "Epoch 173/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8883\n",
      "Epoch 174/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9881\n",
      "Epoch 175/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8386\n",
      "Epoch 176/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8636\n",
      "Epoch 177/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9110\n",
      "Epoch 178/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8677\n",
      "Epoch 179/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8814\n",
      "Epoch 180/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7538\n",
      "Epoch 181/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.6295\n",
      "Epoch 182/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8287\n",
      "Epoch 183/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7995\n",
      "Epoch 184/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0483\n",
      "Epoch 185/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9090\n",
      "Epoch 186/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8894\n",
      "Epoch 187/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.7128\n",
      "Epoch 188/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0893\n",
      "Epoch 189/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.3670\n",
      "Epoch 190/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.1753\n",
      "Epoch 191/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9560\n",
      "Epoch 192/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0600\n",
      "Epoch 193/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9556\n",
      "Epoch 194/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9008\n",
      "Epoch 195/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9996\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 5s 5ms/step - loss: 0.8718\n",
      "Epoch 197/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0644\n",
      "Epoch 198/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0602\n",
      "Epoch 199/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 1.0935\n",
      "Epoch 200/200\n",
      "990/990 [==============================] - 5s 5ms/step - loss: 0.9436\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 512)               225792    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 99)                25443     \n",
      "=================================================================\n",
      "Total params: 3,400,291\n",
      "Trainable params: 3,400,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.fit(deep_input,Y_labels,batch_size=16,epochs=200)\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test input space and save output to a file for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_input_test=np.array(np.append(test_margin_data,test_texture_data,axis=1))\n",
    "deep_input_test=np.array(np.append(deep_input_test,test_shape_data,axis=1))\n",
    "deep_input_test=np.array(np.append(deep_input_test,vocab_test,axis=1))\n",
    "deep_input_test=np.array(np.append(deep_input_test,probs_cnn_test,axis=1))\n",
    "\n",
    "out_file = deep_model.predict(deep_input_test)\n",
    "out_file = np.append(np.array(test_ids).reshape(-1,1),out_file,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishsaha/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# out_file = generateSubmission(test_ids, test_data,svm_model,99)\n",
    "headerRow=np.array(['id'] + le.inverse_transform(range(99)).tolist())\n",
    "df = pd.DataFrame(data=out_file, columns = headerRow)\n",
    "df['id'] = df['id'].astype(np.int)\n",
    "df=df.set_index('id')\n",
    "#print df.head()\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print out_file\n",
    "df.to_csv('output/28_11_18_002(ALexNet15Deep).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
