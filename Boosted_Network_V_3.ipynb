{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pickle\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images first\n",
    "numImages = len(glob.glob('./images/*jpg'))\n",
    "images = [None for i in xrange(numImages)]\n",
    "for fileName in glob.glob('./images/*jpg'):\n",
    "    fileNum = int(fileName[9:][:-4])\n",
    "    images[fileNum-1] = np.array(cv2.imread(fileName))\n",
    "images = np.array(images)\n",
    "\n",
    "# Load csv data next\n",
    "train_data = pd.read_csv('data/train.csv').drop(['species'], axis=1).values\n",
    "train_labels = pd.read_csv('data/train.csv')['species'].values\n",
    "labels=train_labels.tolist()\n",
    "train_images = [images[int(data[0]-1)] for data in train_data]\n",
    "train_ids = [data[0] for data in train_data]\n",
    "train_data = np.delete(train_data, 0, 1)\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('data/test.csv').values\n",
    "test_images = [images[int(data[0]-1)] for data in test_data]\n",
    "test_ids = [data[0] for data in test_data]\n",
    "test_data = np.delete(test_data, 0, 1)\n",
    "\n",
    "del images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Image Normalization and Mini-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN train data\n",
    "def img_norm(img):\n",
    "    t= 2 * (np.float32(img) / 255 - 0.5) # normalize img pixels to [-1, 1]\n",
    "    return t\n",
    "def minibatchData(data,labels_encoded,img_size,channel_num=3,batch_num=30):\n",
    "    images=[]\n",
    "    for img in data:\n",
    "        images.append(np.transpose(img_norm(cv2.resize(img,img_size)),[2,0,1]))\n",
    "    \n",
    "    \n",
    "    if batch_num > 1:\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        print(len(images))\n",
    "        print(batch_num)\n",
    "        \n",
    "        for i in range(int(len(images) / batch_num)):\n",
    "            minibatch_d = images[i*batch_num: (i+1)*batch_num]\n",
    "            minibatch_d = np.reshape(minibatch_d, (batch_num, channel_num,img_size[0],img_size[1]))\n",
    "            batch_data.append(torch.from_numpy(minibatch_d))\n",
    "            if labels_encoded is not None:\n",
    "                minibatch_l = labels_encoded[i*batch_num: (i+1)*batch_num]\n",
    "                batch_labels.append(torch.LongTensor(minibatch_l))\n",
    "            else:\n",
    "                minibatch_l = np.zeros(batch_num)\n",
    "                batch_labels.append(torch.LongTensor(minibatch_l))\n",
    "        #data, labels = batch_data, batch_labels \n",
    "        \n",
    "    return zip(batch_data, batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare image label encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le= preprocessing.LabelEncoder()\n",
    "#encode train labels\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded=le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "img_size=(224,224)\n",
    "cnn_train_data = list(minibatchData(train_images,train_labels_encoded,img_size))\n",
    "#plt.imshow(cnn_train_data[0][0][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a6fa15850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_test_data = list(minibatchData(test_images,None,img_size,batch_num=2))\n",
    "#print cnn_train_data.size\n",
    "plt.imshow(cnn_test_data[0][0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved alexnet from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='tunedAlex.sav'\n",
    "model_ft = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the CNN Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 99)\n"
     ]
    }
   ],
   "source": [
    "probs_cnn_train=np.empty([0,99])\n",
    "#sm = torch.nn.Softmax()\n",
    "for data in cnn_train_data:\n",
    "    images,labels=data\n",
    "    probs_cnn_train=np.append(probs_cnn_train,(model_ft(images)).data.numpy(),axis=0)\n",
    "print probs_cnn_train.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the CNN Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 99)\n"
     ]
    }
   ],
   "source": [
    "probs_cnn_test=np.empty([0,99])\n",
    "for data in cnn_test_data:\n",
    "    images, labels = data\n",
    "    probs_cnn_test=np.append(probs_cnn_test,(model_ft(images)).data.numpy(),axis=0)\n",
    "    #outputs=np.append(outputs,net(images).data.numpy(),axis=0)\n",
    "    #print probs\n",
    "    \n",
    "\n",
    "print probs_cnn_test.shape\n",
    "\n",
    "#sm = torch.nn.Softmax()\n",
    "#probabilities = sm(output) \n",
    "#print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the test/train logical partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the 3 histograms\n",
    "train_margin_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'margin1':'margin64']).values\n",
    "train_shape_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'shape1':'shape64']).values\n",
    "train_texture_data=((pd.read_csv('data/train.csv').drop(['species'], axis=1)).loc[:,'texture1':'texture64']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_margin_data=((pd.read_csv('data/test.csv')).loc[:,'margin1':'margin64']).values\n",
    "test_shape_data=((pd.read_csv('data/test.csv')).loc[:,'shape1':'shape64']).values\n",
    "test_texture_data=((pd.read_csv('data/test.csv')).loc[:,'texture1':'texture64']).values\n",
    "\n",
    "#print train_margin_data.head()\n",
    "#print train_shape_data.head()\n",
    "#print train_texture_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(images, dense=False):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    des_per_Img = np.array([sift.detectAndCompute(img,None)[1] for img in images])\n",
    "    return des_per_Img\n",
    "        \n",
    "def get_clusters(descriptors, vocabSize):\n",
    "    des_list = np.concatenate(descriptors)\n",
    "\n",
    "    kmeans = MiniBatchKMeans(vocabSize, batch_size=100)\n",
    "    kmeans.fit(np.array(des_list))\n",
    "    \n",
    "    return kmeans\n",
    "\n",
    "def get_vocabulary(descriptors, clusters, vocabSize):\n",
    "    return np.array([normalize(np.histogram(clusters.predict(dscrs), bins=range(vocabSize))[0].reshape(1,-1)).ravel() for dscrs in descriptors])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors computed in 133.268115 seconds\n"
     ]
    }
   ],
   "source": [
    "des_start_time =time.time()\n",
    "des_list_train = get_descriptor(train_images)\n",
    "\n",
    "des_list_test = get_descriptor(test_images)\n",
    "des_end_time =time.time()\n",
    "print \"Descriptors computed in {:2f} seconds\".format(des_end_time-des_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering completed in 2.823910 seconds\n"
     ]
    }
   ],
   "source": [
    "clustering_start_time=time.time()\n",
    "clusters = get_clusters(des_list_train,150)\n",
    "clustering_end_time=time.time()\n",
    "print \"Clustering completed in {:2f} seconds\".format(clustering_end_time-clustering_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 149)\n"
     ]
    }
   ],
   "source": [
    "vocab_train = get_vocabulary(des_list_train,clusters,150)\n",
    "vocab_test = get_vocabulary(des_list_test,clusters,150)\n",
    "\n",
    "print vocab_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the weak learners as Keras Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.utils import np_utils\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_shape = Sequential([Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu'), Dense(99, activation='softmax')])\n",
    "deep_texture = Sequential([Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu'), Dense(99, activation='softmax')])\n",
    "deep_margin = Sequential([Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu'), Dense(99, activation='softmax')])\n",
    "deep_sift = Sequential([Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu'), Dense(99, activation='softmax')])\n",
    "deep_alex = Sequential([Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu'), Dense(99, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_shape.compile(loss='categorical_crossentropy', optimizer='adam', metric=[keras.metrics.categorical_accuracy])\n",
    "deep_texture.compile(loss='categorical_crossentropy', optimizer='adam', metric=[keras.metrics.categorical_accuracy])\n",
    "deep_margin.compile(loss='categorical_crossentropy', optimizer='adam', metric=[keras.metrics.categorical_accuracy])\n",
    "deep_sift.compile(loss='categorical_crossentropy', optimizer='adam', metric=[keras.metrics.categorical_accuracy])\n",
    "deep_alex.compile(loss='categorical_crossentropy', optimizer='adam', metric=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 5.0129\n",
      "Epoch 2/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 2.6516\n",
      "Epoch 3/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 1.5004\n",
      "Epoch 4/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 1.0199\n",
      "Epoch 5/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.7763\n",
      "Epoch 6/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.5943\n",
      "Epoch 7/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.5314\n",
      "Epoch 8/150\n",
      "990/990 [==============================] - 0s 333us/step - loss: 0.4401\n",
      "Epoch 9/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.3728\n",
      "Epoch 10/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.3075\n",
      "Epoch 11/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.3162\n",
      "Epoch 12/150\n",
      "990/990 [==============================] - 0s 450us/step - loss: 0.2697\n",
      "Epoch 13/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.2557\n",
      "Epoch 14/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 0.2281\n",
      "Epoch 15/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.1946\n",
      "Epoch 16/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.1898\n",
      "Epoch 17/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.1918\n",
      "Epoch 18/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1751\n",
      "Epoch 19/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1813\n",
      "Epoch 20/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1763\n",
      "Epoch 21/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.1893\n",
      "Epoch 22/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.1625\n",
      "Epoch 23/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.1437\n",
      "Epoch 24/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.1476\n",
      "Epoch 25/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.1189\n",
      "Epoch 26/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.1579\n",
      "Epoch 27/150\n",
      "990/990 [==============================] - 0s 330us/step - loss: 0.1242\n",
      "Epoch 28/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.1612\n",
      "Epoch 29/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.1360\n",
      "Epoch 30/150\n",
      "990/990 [==============================] - 0s 330us/step - loss: 0.1283\n",
      "Epoch 31/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.1348\n",
      "Epoch 32/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1376\n",
      "Epoch 33/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.1284\n",
      "Epoch 34/150\n",
      "990/990 [==============================] - 0s 337us/step - loss: 0.1149\n",
      "Epoch 35/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0802\n",
      "Epoch 36/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.1028\n",
      "Epoch 37/150\n",
      "990/990 [==============================] - 0s 334us/step - loss: 0.1246\n",
      "Epoch 38/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.1704\n",
      "Epoch 39/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.1414\n",
      "Epoch 40/150\n",
      "990/990 [==============================] - 0s 330us/step - loss: 0.1117\n",
      "Epoch 41/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.1021\n",
      "Epoch 42/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.1031\n",
      "Epoch 43/150\n",
      "990/990 [==============================] - 0s 330us/step - loss: 0.1271\n",
      "Epoch 44/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.1125\n",
      "Epoch 45/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.0945\n",
      "Epoch 46/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1081\n",
      "Epoch 47/150\n",
      "990/990 [==============================] - 0s 343us/step - loss: 0.0806\n",
      "Epoch 48/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.0873\n",
      "Epoch 49/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.0916\n",
      "Epoch 50/150\n",
      "990/990 [==============================] - 0s 332us/step - loss: 0.0867\n",
      "Epoch 51/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1231\n",
      "Epoch 52/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1190\n",
      "Epoch 53/150\n",
      "990/990 [==============================] - 0s 336us/step - loss: 0.1294\n",
      "Epoch 54/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.1490\n",
      "Epoch 55/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1703\n",
      "Epoch 56/150\n",
      "990/990 [==============================] - 0s 328us/step - loss: 0.0960\n",
      "Epoch 57/150\n",
      "990/990 [==============================] - 0s 339us/step - loss: 0.1001\n",
      "Epoch 58/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0812\n",
      "Epoch 59/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1107\n",
      "Epoch 60/150\n",
      "990/990 [==============================] - 0s 336us/step - loss: 0.0979\n",
      "Epoch 61/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.0946\n",
      "Epoch 62/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1079\n",
      "Epoch 63/150\n",
      "990/990 [==============================] - 0s 331us/step - loss: 0.0934\n",
      "Epoch 64/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1334\n",
      "Epoch 65/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1064\n",
      "Epoch 66/150\n",
      "990/990 [==============================] - 0s 337us/step - loss: 0.1154\n",
      "Epoch 67/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1084\n",
      "Epoch 68/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.1440\n",
      "Epoch 69/150\n",
      "990/990 [==============================] - 0s 333us/step - loss: 0.1398\n",
      "Epoch 70/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.1153\n",
      "Epoch 71/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.1155\n",
      "Epoch 72/150\n",
      "990/990 [==============================] - 0s 331us/step - loss: 0.0804\n",
      "Epoch 73/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.0649\n",
      "Epoch 74/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0766\n",
      "Epoch 75/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.0572\n",
      "Epoch 76/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.0895\n",
      "Epoch 77/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0881\n",
      "Epoch 78/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0673\n",
      "Epoch 79/150\n",
      "990/990 [==============================] - 0s 342us/step - loss: 0.1298\n",
      "Epoch 80/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.0958\n",
      "Epoch 81/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0468\n",
      "Epoch 82/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.0873\n",
      "Epoch 83/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.1232\n",
      "Epoch 84/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.1195\n",
      "Epoch 85/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0978\n",
      "Epoch 86/150\n",
      "990/990 [==============================] - 0s 334us/step - loss: 0.0684\n",
      "Epoch 87/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0474\n",
      "Epoch 88/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.0540\n",
      "Epoch 89/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.0840\n",
      "Epoch 90/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.0665\n",
      "Epoch 91/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0759\n",
      "Epoch 92/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.1071\n",
      "Epoch 93/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0480\n",
      "Epoch 94/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0818\n",
      "Epoch 95/150\n",
      "990/990 [==============================] - 0s 330us/step - loss: 0.1117\n",
      "Epoch 96/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.0782\n",
      "Epoch 97/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.0565\n",
      "Epoch 98/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.0721\n",
      "Epoch 99/150\n",
      "990/990 [==============================] - 0s 328us/step - loss: 0.0716\n",
      "Epoch 100/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.0667\n",
      "Epoch 101/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.1238\n",
      "Epoch 102/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.0447\n",
      "Epoch 103/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.0476\n",
      "Epoch 104/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0910\n",
      "Epoch 105/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.0862\n",
      "Epoch 106/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0925\n",
      "Epoch 107/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.0907\n",
      "Epoch 108/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.0909\n",
      "Epoch 109/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.0905\n",
      "Epoch 110/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.0822\n",
      "Epoch 111/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.0516\n",
      "Epoch 112/150\n",
      "990/990 [==============================] - 0s 340us/step - loss: 0.1160\n",
      "Epoch 113/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.0668\n",
      "Epoch 114/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.1168\n",
      "Epoch 115/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.1177\n",
      "Epoch 116/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.0615\n",
      "Epoch 117/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.0735\n",
      "Epoch 118/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.0603\n",
      "Epoch 119/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.0729\n",
      "Epoch 120/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.0456\n",
      "Epoch 121/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.1317\n",
      "Epoch 122/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.0847\n",
      "Epoch 123/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.0908\n",
      "Epoch 124/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.0991\n",
      "Epoch 125/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.0889\n",
      "Epoch 126/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.1210\n",
      "Epoch 127/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.0754\n",
      "Epoch 128/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.0825\n",
      "Epoch 129/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.0741\n",
      "Epoch 130/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.0875\n",
      "Epoch 131/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.0818\n",
      "Epoch 132/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.0820\n",
      "Epoch 133/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.1203\n",
      "Epoch 134/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.1136\n",
      "Epoch 135/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.0596\n",
      "Epoch 136/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.0970\n",
      "Epoch 137/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.1082\n",
      "Epoch 138/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.0707\n",
      "Epoch 139/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.0766\n",
      "Epoch 140/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.0472\n",
      "Epoch 141/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.0440\n",
      "Epoch 142/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.0579\n",
      "Epoch 143/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.0441\n",
      "Epoch 144/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.0697\n",
      "Epoch 145/150\n",
      "990/990 [==============================] - 0s 343us/step - loss: 0.0747\n",
      "Epoch 146/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.0813\n",
      "Epoch 147/150\n",
      "990/990 [==============================] - 0s 336us/step - loss: 0.0883\n",
      "Epoch 148/150\n",
      "990/990 [==============================] - 0s 353us/step - loss: 0.0899\n",
      "Epoch 149/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 0.1123\n",
      "Epoch 150/150\n",
      "990/990 [==============================] - 0s 479us/step - loss: 0.0621\n",
      "Epoch 1/150\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 4.5975\n",
      "Epoch 2/150\n",
      "990/990 [==============================] - 0s 410us/step - loss: 4.5963\n",
      "Epoch 3/150\n",
      "990/990 [==============================] - 0s 455us/step - loss: 4.5964\n",
      "Epoch 4/150\n",
      "990/990 [==============================] - 0s 370us/step - loss: 4.5964\n",
      "Epoch 5/150\n",
      "990/990 [==============================] - 0s 339us/step - loss: 4.5962\n",
      "Epoch 6/150\n",
      "990/990 [==============================] - 0s 475us/step - loss: 4.5962\n",
      "Epoch 7/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 4.5960\n",
      "Epoch 8/150\n",
      "990/990 [==============================] - 0s 370us/step - loss: 4.5960\n",
      "Epoch 9/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 4.5960\n",
      "Epoch 10/150\n",
      "990/990 [==============================] - 0s 332us/step - loss: 4.5960\n",
      "Epoch 11/150\n",
      "990/990 [==============================] - 0s 393us/step - loss: 4.5960\n",
      "Epoch 12/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 4.5960\n",
      "Epoch 13/150\n",
      "990/990 [==============================] - 0s 401us/step - loss: 4.5958\n",
      "Epoch 14/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 4.5957\n",
      "Epoch 15/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 4.5950\n",
      "Epoch 16/150\n",
      "990/990 [==============================] - 0s 441us/step - loss: 4.5942\n",
      "Epoch 17/150\n",
      "990/990 [==============================] - 0s 469us/step - loss: 4.5921\n",
      "Epoch 18/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 4.5878\n",
      "Epoch 19/150\n",
      "990/990 [==============================] - 0s 389us/step - loss: 4.5789\n",
      "Epoch 20/150\n",
      "990/990 [==============================] - 0s 409us/step - loss: 4.5607\n",
      "Epoch 21/150\n",
      "990/990 [==============================] - 0s 404us/step - loss: 4.5296\n",
      "Epoch 22/150\n",
      "990/990 [==============================] - 0s 424us/step - loss: 4.4906\n",
      "Epoch 23/150\n",
      "990/990 [==============================] - 0s 399us/step - loss: 4.4268\n",
      "Epoch 24/150\n",
      "990/990 [==============================] - 0s 469us/step - loss: 4.3731\n",
      "Epoch 25/150\n",
      "990/990 [==============================] - 1s 508us/step - loss: 4.3050\n",
      "Epoch 26/150\n",
      "990/990 [==============================] - 0s 390us/step - loss: 4.2551\n",
      "Epoch 27/150\n",
      "990/990 [==============================] - 0s 432us/step - loss: 4.2189\n",
      "Epoch 28/150\n",
      "990/990 [==============================] - 0s 407us/step - loss: 4.1748\n",
      "Epoch 29/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 4.1487\n",
      "Epoch 30/150\n",
      "990/990 [==============================] - 0s 327us/step - loss: 4.0952\n",
      "Epoch 31/150\n",
      "990/990 [==============================] - 0s 386us/step - loss: 4.0828\n",
      "Epoch 32/150\n",
      "990/990 [==============================] - 0s 406us/step - loss: 4.0567\n",
      "Epoch 33/150\n",
      "990/990 [==============================] - 0s 342us/step - loss: 4.0488\n",
      "Epoch 34/150\n",
      "990/990 [==============================] - 0s 362us/step - loss: 4.0280\n",
      "Epoch 35/150\n",
      "990/990 [==============================] - 0s 374us/step - loss: 4.0170\n",
      "Epoch 36/150\n",
      "990/990 [==============================] - 0s 444us/step - loss: 4.0009\n",
      "Epoch 37/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 3.9962\n",
      "Epoch 38/150\n",
      "990/990 [==============================] - 0s 421us/step - loss: 3.9643\n",
      "Epoch 39/150\n",
      "990/990 [==============================] - 0s 417us/step - loss: 3.9479\n",
      "Epoch 40/150\n",
      "990/990 [==============================] - 0s 417us/step - loss: 3.9409\n",
      "Epoch 41/150\n",
      "990/990 [==============================] - 0s 451us/step - loss: 3.9313\n",
      "Epoch 42/150\n",
      "990/990 [==============================] - 0s 354us/step - loss: 3.9409\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 313us/step - loss: 3.9127\n",
      "Epoch 44/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 3.9198\n",
      "Epoch 45/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 3.9032\n",
      "Epoch 46/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 3.8993\n",
      "Epoch 47/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.8924\n",
      "Epoch 48/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 3.8783\n",
      "Epoch 49/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 3.8554\n",
      "Epoch 50/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 3.8529\n",
      "Epoch 51/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 3.8783\n",
      "Epoch 52/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 3.8512\n",
      "Epoch 53/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 3.8210\n",
      "Epoch 54/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 3.8467\n",
      "Epoch 55/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 3.8373\n",
      "Epoch 56/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 3.8469\n",
      "Epoch 57/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 3.8357\n",
      "Epoch 58/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.8228\n",
      "Epoch 59/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 3.8186\n",
      "Epoch 60/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 3.8178\n",
      "Epoch 61/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.8098\n",
      "Epoch 62/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 3.8652\n",
      "Epoch 63/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 3.8243\n",
      "Epoch 64/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.8384\n",
      "Epoch 65/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 3.8331\n",
      "Epoch 66/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.8223\n",
      "Epoch 67/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.8229\n",
      "Epoch 68/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.7931\n",
      "Epoch 69/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 3.7947\n",
      "Epoch 70/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 3.7875\n",
      "Epoch 71/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 3.7991\n",
      "Epoch 72/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 3.7963\n",
      "Epoch 73/150\n",
      "990/990 [==============================] - 0s 305us/step - loss: 3.7771\n",
      "Epoch 74/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.7740\n",
      "Epoch 75/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.7431\n",
      "Epoch 76/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.7647\n",
      "Epoch 77/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 3.7772\n",
      "Epoch 78/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 3.7681\n",
      "Epoch 79/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.7654\n",
      "Epoch 80/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.7999\n",
      "Epoch 81/150\n",
      "990/990 [==============================] - 0s 392us/step - loss: 3.7438\n",
      "Epoch 82/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 3.7994\n",
      "Epoch 83/150\n",
      "990/990 [==============================] - 0s 376us/step - loss: 3.7831\n",
      "Epoch 84/150\n",
      "990/990 [==============================] - 0s 365us/step - loss: 3.7516\n",
      "Epoch 85/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 3.7486\n",
      "Epoch 86/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 3.7392\n",
      "Epoch 87/150\n",
      "990/990 [==============================] - 0s 393us/step - loss: 3.7574\n",
      "Epoch 88/150\n",
      "990/990 [==============================] - 0s 368us/step - loss: 3.7515\n",
      "Epoch 89/150\n",
      "990/990 [==============================] - 0s 409us/step - loss: 3.7400\n",
      "Epoch 90/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 3.7467\n",
      "Epoch 91/150\n",
      "990/990 [==============================] - 0s 341us/step - loss: 3.7518\n",
      "Epoch 92/150\n",
      "990/990 [==============================] - 0s 389us/step - loss: 3.7240\n",
      "Epoch 93/150\n",
      "990/990 [==============================] - 0s 385us/step - loss: 3.7324\n",
      "Epoch 94/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.7396\n",
      "Epoch 95/150\n",
      "990/990 [==============================] - 0s 363us/step - loss: 3.7400\n",
      "Epoch 96/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 3.7101\n",
      "Epoch 97/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 3.7114\n",
      "Epoch 98/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 3.7283\n",
      "Epoch 99/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 3.7212\n",
      "Epoch 100/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 3.7163\n",
      "Epoch 101/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 3.6836\n",
      "Epoch 102/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.7125\n",
      "Epoch 103/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.7199\n",
      "Epoch 104/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.6948\n",
      "Epoch 105/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.6937\n",
      "Epoch 106/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.7428\n",
      "Epoch 107/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 3.7218\n",
      "Epoch 108/150\n",
      "990/990 [==============================] - 0s 338us/step - loss: 3.6962\n",
      "Epoch 109/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.6758\n",
      "Epoch 110/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.7091\n",
      "Epoch 111/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 3.6966\n",
      "Epoch 112/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.6907\n",
      "Epoch 113/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.6943\n",
      "Epoch 114/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 3.6367\n",
      "Epoch 115/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 3.6613\n",
      "Epoch 116/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.6571\n",
      "Epoch 117/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 3.6828\n",
      "Epoch 118/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 3.6448\n",
      "Epoch 119/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.6470\n",
      "Epoch 120/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.6460\n",
      "Epoch 121/150\n",
      "990/990 [==============================] - 0s 332us/step - loss: 3.6772\n",
      "Epoch 122/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 3.6747\n",
      "Epoch 123/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 3.6598\n",
      "Epoch 124/150\n",
      "990/990 [==============================] - 0s 334us/step - loss: 3.6362\n",
      "Epoch 125/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 3.6632\n",
      "Epoch 126/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 3.6465\n",
      "Epoch 127/150\n",
      "990/990 [==============================] - 0s 424us/step - loss: 3.6892\n",
      "Epoch 128/150\n",
      "990/990 [==============================] - 0s 377us/step - loss: 3.6718\n",
      "Epoch 129/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 3.6651\n",
      "Epoch 130/150\n",
      "990/990 [==============================] - 0s 409us/step - loss: 3.6114\n",
      "Epoch 131/150\n",
      "990/990 [==============================] - 0s 373us/step - loss: 3.6428\n",
      "Epoch 132/150\n",
      "990/990 [==============================] - 0s 369us/step - loss: 3.6262\n",
      "Epoch 133/150\n",
      "990/990 [==============================] - 0s 367us/step - loss: 3.6459\n",
      "Epoch 134/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.6504\n",
      "Epoch 135/150\n",
      "990/990 [==============================] - 0s 337us/step - loss: 3.6101\n",
      "Epoch 136/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 3.6160\n",
      "Epoch 137/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 3.6030\n",
      "Epoch 138/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 3.6224\n",
      "Epoch 139/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 324us/step - loss: 3.6289\n",
      "Epoch 140/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 3.6085\n",
      "Epoch 141/150\n",
      "990/990 [==============================] - 0s 304us/step - loss: 3.6070\n",
      "Epoch 142/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 3.6243\n",
      "Epoch 143/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 3.6181 0s - loss: 3.6\n",
      "Epoch 144/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 3.6134\n",
      "Epoch 145/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.6229\n",
      "Epoch 146/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 3.6321\n",
      "Epoch 147/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 3.6675\n",
      "Epoch 148/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.5987\n",
      "Epoch 149/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 3.6486\n",
      "Epoch 150/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 3.5933\n",
      "Epoch 1/150\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 4.5864\n",
      "Epoch 2/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 4.4919\n",
      "Epoch 3/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 4.0943\n",
      "Epoch 4/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 3.4677\n",
      "Epoch 5/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 2.9720\n",
      "Epoch 6/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 2.6617\n",
      "Epoch 7/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 2.4134\n",
      "Epoch 8/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 2.2575\n",
      "Epoch 9/150\n",
      "990/990 [==============================] - 0s 305us/step - loss: 2.0889\n",
      "Epoch 10/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 1.9517\n",
      "Epoch 11/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 1.8605\n",
      "Epoch 12/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 1.7876\n",
      "Epoch 13/150\n",
      "990/990 [==============================] - 0s 327us/step - loss: 1.6706\n",
      "Epoch 14/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 1.6340\n",
      "Epoch 15/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 1.5461\n",
      "Epoch 16/150\n",
      "990/990 [==============================] - 0s 328us/step - loss: 1.4892\n",
      "Epoch 17/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 1.4734\n",
      "Epoch 18/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 1.3858\n",
      "Epoch 19/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 1.3533\n",
      "Epoch 20/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 1.3398\n",
      "Epoch 21/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 1.2610\n",
      "Epoch 22/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 1.2123\n",
      "Epoch 23/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 1.1968\n",
      "Epoch 24/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 1.1878\n",
      "Epoch 25/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 1.1523\n",
      "Epoch 26/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 1.1206\n",
      "Epoch 27/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 1.1112\n",
      "Epoch 28/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 1.0839\n",
      "Epoch 29/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 1.0497\n",
      "Epoch 30/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 1.0000\n",
      "Epoch 31/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 1.0345\n",
      "Epoch 32/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.9780\n",
      "Epoch 33/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.9857\n",
      "Epoch 34/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.9002\n",
      "Epoch 35/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.8750\n",
      "Epoch 36/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.9044\n",
      "Epoch 37/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.8793\n",
      "Epoch 38/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.8830\n",
      "Epoch 39/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.8793\n",
      "Epoch 40/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.8728\n",
      "Epoch 41/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 0.8478\n",
      "Epoch 42/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.8241\n",
      "Epoch 43/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.8009\n",
      "Epoch 44/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.7603\n",
      "Epoch 45/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.7647\n",
      "Epoch 46/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.7358\n",
      "Epoch 47/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.7488\n",
      "Epoch 48/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.7516\n",
      "Epoch 49/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.7110\n",
      "Epoch 50/150\n",
      "990/990 [==============================] - 0s 335us/step - loss: 0.6985\n",
      "Epoch 51/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.6618\n",
      "Epoch 52/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.7073 0s - loss: 0\n",
      "Epoch 53/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.6903\n",
      "Epoch 54/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.6677\n",
      "Epoch 55/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.6554\n",
      "Epoch 56/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.6622\n",
      "Epoch 57/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.6265\n",
      "Epoch 58/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.6124\n",
      "Epoch 59/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.6430\n",
      "Epoch 60/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.6198\n",
      "Epoch 61/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.6075\n",
      "Epoch 62/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.5868\n",
      "Epoch 63/150\n",
      "990/990 [==============================] - 0s 385us/step - loss: 0.6125\n",
      "Epoch 64/150\n",
      "990/990 [==============================] - 0s 393us/step - loss: 0.5884\n",
      "Epoch 65/150\n",
      "990/990 [==============================] - 0s 367us/step - loss: 0.5605\n",
      "Epoch 66/150\n",
      "990/990 [==============================] - 0s 414us/step - loss: 0.5846\n",
      "Epoch 67/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 0.5555\n",
      "Epoch 68/150\n",
      "990/990 [==============================] - 0s 406us/step - loss: 0.5461\n",
      "Epoch 69/150\n",
      "990/990 [==============================] - 0s 376us/step - loss: 0.5606\n",
      "Epoch 70/150\n",
      "990/990 [==============================] - 0s 396us/step - loss: 0.5151\n",
      "Epoch 71/150\n",
      "990/990 [==============================] - 0s 383us/step - loss: 0.5085\n",
      "Epoch 72/150\n",
      "990/990 [==============================] - 0s 385us/step - loss: 0.5187\n",
      "Epoch 73/150\n",
      "990/990 [==============================] - 0s 389us/step - loss: 0.5197\n",
      "Epoch 74/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 0.4879\n",
      "Epoch 75/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.4991\n",
      "Epoch 76/150\n",
      "990/990 [==============================] - 0s 434us/step - loss: 0.4924\n",
      "Epoch 77/150\n",
      "990/990 [==============================] - 0s 413us/step - loss: 0.4926\n",
      "Epoch 78/150\n",
      "990/990 [==============================] - 0s 456us/step - loss: 0.4943\n",
      "Epoch 79/150\n",
      "990/990 [==============================] - 0s 467us/step - loss: 0.5005\n",
      "Epoch 80/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.4501\n",
      "Epoch 81/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.4525\n",
      "Epoch 82/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.4510\n",
      "Epoch 83/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.4423\n",
      "Epoch 84/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.4072\n",
      "Epoch 85/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.4467\n",
      "Epoch 86/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.4438\n",
      "Epoch 87/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.4148\n",
      "Epoch 88/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.4215\n",
      "Epoch 89/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.4325\n",
      "Epoch 90/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 0.3978\n",
      "Epoch 91/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.4231\n",
      "Epoch 92/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.3978\n",
      "Epoch 93/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.4098\n",
      "Epoch 94/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.3971\n",
      "Epoch 95/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.3874\n",
      "Epoch 96/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.3644\n",
      "Epoch 97/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.3697\n",
      "Epoch 98/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.3596\n",
      "Epoch 99/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.3670\n",
      "Epoch 100/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 0.3724\n",
      "Epoch 101/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.3615\n",
      "Epoch 102/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.3541\n",
      "Epoch 103/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.3532\n",
      "Epoch 104/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.3414\n",
      "Epoch 105/150\n",
      "990/990 [==============================] - 0s 334us/step - loss: 0.3448\n",
      "Epoch 106/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.3286\n",
      "Epoch 107/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.3217\n",
      "Epoch 108/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.3250\n",
      "Epoch 109/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.3623\n",
      "Epoch 110/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.2896\n",
      "Epoch 111/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.3185\n",
      "Epoch 112/150\n",
      "990/990 [==============================] - 0s 335us/step - loss: 0.3156\n",
      "Epoch 113/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.3170\n",
      "Epoch 114/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.2824\n",
      "Epoch 115/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.3195\n",
      "Epoch 116/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.3020\n",
      "Epoch 117/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2882\n",
      "Epoch 118/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.3026\n",
      "Epoch 119/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.2795\n",
      "Epoch 120/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 0.2896\n",
      "Epoch 121/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.2549\n",
      "Epoch 122/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.2811\n",
      "Epoch 123/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.2987\n",
      "Epoch 124/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2628\n",
      "Epoch 125/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.2775\n",
      "Epoch 126/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2613\n",
      "Epoch 127/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.3009\n",
      "Epoch 128/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 0.2566\n",
      "Epoch 129/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.2485\n",
      "Epoch 130/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.2490\n",
      "Epoch 131/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2763\n",
      "Epoch 132/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.2446\n",
      "Epoch 133/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2470\n",
      "Epoch 134/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.2543\n",
      "Epoch 135/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.2458\n",
      "Epoch 136/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.2704\n",
      "Epoch 137/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.2542\n",
      "Epoch 138/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.2361\n",
      "Epoch 139/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.2422\n",
      "Epoch 140/150\n",
      "990/990 [==============================] - 0s 306us/step - loss: 0.2300\n",
      "Epoch 141/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.2408\n",
      "Epoch 142/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.2197\n",
      "Epoch 143/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.2380\n",
      "Epoch 144/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.2212\n",
      "Epoch 145/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.2178\n",
      "Epoch 146/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.2000\n",
      "Epoch 147/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 0.2186\n",
      "Epoch 148/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.2175\n",
      "Epoch 149/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.1923\n",
      "Epoch 150/150\n",
      "990/990 [==============================] - 0s 307us/step - loss: 0.1894\n",
      "Epoch 1/150\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 4.5907\n",
      "Epoch 2/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 4.5029\n",
      "Epoch 3/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 4.0724\n",
      "Epoch 4/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 3.5363\n",
      "Epoch 5/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 3.1115\n",
      "Epoch 6/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 2.7768\n",
      "Epoch 7/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 2.5016\n",
      "Epoch 8/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 2.2491\n",
      "Epoch 9/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 2.0838\n",
      "Epoch 10/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 1.9700\n",
      "Epoch 11/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 1.8416\n",
      "Epoch 12/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 1.7581\n",
      "Epoch 13/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 1.6535\n",
      "Epoch 14/150\n",
      "990/990 [==============================] - 0s 308us/step - loss: 1.6118\n",
      "Epoch 15/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 1.5778\n",
      "Epoch 16/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 1.4699\n",
      "Epoch 17/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 1.4594\n",
      "Epoch 18/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 1.4116\n",
      "Epoch 19/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 1.4034\n",
      "Epoch 20/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 1.3343\n",
      "Epoch 21/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 1.3011\n",
      "Epoch 22/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 1.3162\n",
      "Epoch 23/150\n",
      "990/990 [==============================] - 0s 332us/step - loss: 1.2626\n",
      "Epoch 24/150\n",
      "990/990 [==============================] - 0s 335us/step - loss: 1.2486\n",
      "Epoch 25/150\n",
      "990/990 [==============================] - 0s 339us/step - loss: 1.2428\n",
      "Epoch 26/150\n",
      "990/990 [==============================] - 0s 368us/step - loss: 1.1794\n",
      "Epoch 27/150\n",
      "990/990 [==============================] - 0s 415us/step - loss: 1.1637\n",
      "Epoch 28/150\n",
      "990/990 [==============================] - 0s 409us/step - loss: 1.1298\n",
      "Epoch 29/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 1.1160\n",
      "Epoch 30/150\n",
      "990/990 [==============================] - 0s 446us/step - loss: 1.1112\n",
      "Epoch 31/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 376us/step - loss: 1.0961\n",
      "Epoch 32/150\n",
      "990/990 [==============================] - 0s 407us/step - loss: 1.0997\n",
      "Epoch 33/150\n",
      "990/990 [==============================] - 0s 443us/step - loss: 1.0685\n",
      "Epoch 34/150\n",
      "990/990 [==============================] - 0s 412us/step - loss: 1.0235\n",
      "Epoch 35/150\n",
      "990/990 [==============================] - 0s 448us/step - loss: 1.0014\n",
      "Epoch 36/150\n",
      "990/990 [==============================] - 0s 467us/step - loss: 1.0066\n",
      "Epoch 37/150\n",
      "990/990 [==============================] - 0s 335us/step - loss: 1.0082\n",
      "Epoch 38/150\n",
      "990/990 [==============================] - 0s 371us/step - loss: 0.9941\n",
      "Epoch 39/150\n",
      "990/990 [==============================] - 0s 415us/step - loss: 0.9854\n",
      "Epoch 40/150\n",
      "990/990 [==============================] - 0s 384us/step - loss: 0.9927\n",
      "Epoch 41/150\n",
      "990/990 [==============================] - 0s 390us/step - loss: 0.9746\n",
      "Epoch 42/150\n",
      "990/990 [==============================] - 0s 365us/step - loss: 0.9328\n",
      "Epoch 43/150\n",
      "990/990 [==============================] - 0s 390us/step - loss: 0.9352\n",
      "Epoch 44/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 0.9385\n",
      "Epoch 45/150\n",
      "990/990 [==============================] - 0s 398us/step - loss: 0.8909\n",
      "Epoch 46/150\n",
      "990/990 [==============================] - 0s 420us/step - loss: 0.9207\n",
      "Epoch 47/150\n",
      "990/990 [==============================] - 0s 395us/step - loss: 0.9069\n",
      "Epoch 48/150\n",
      "990/990 [==============================] - 0s 401us/step - loss: 0.8921\n",
      "Epoch 49/150\n",
      "990/990 [==============================] - 0s 339us/step - loss: 0.8880\n",
      "Epoch 50/150\n",
      "990/990 [==============================] - 0s 423us/step - loss: 0.8453\n",
      "Epoch 51/150\n",
      "990/990 [==============================] - 0s 485us/step - loss: 0.8499\n",
      "Epoch 52/150\n",
      "990/990 [==============================] - 0s 467us/step - loss: 0.8565\n",
      "Epoch 53/150\n",
      "990/990 [==============================] - 0s 361us/step - loss: 0.8350\n",
      "Epoch 54/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.8390\n",
      "Epoch 55/150\n",
      "990/990 [==============================] - 0s 369us/step - loss: 0.8352\n",
      "Epoch 56/150\n",
      "990/990 [==============================] - 0s 407us/step - loss: 0.7887\n",
      "Epoch 57/150\n",
      "990/990 [==============================] - 0s 366us/step - loss: 0.7973\n",
      "Epoch 58/150\n",
      "990/990 [==============================] - 0s 382us/step - loss: 0.7939\n",
      "Epoch 59/150\n",
      "990/990 [==============================] - 0s 421us/step - loss: 0.8097\n",
      "Epoch 60/150\n",
      "990/990 [==============================] - 0s 424us/step - loss: 0.7744\n",
      "Epoch 61/150\n",
      "990/990 [==============================] - 0s 352us/step - loss: 0.7888\n",
      "Epoch 62/150\n",
      "990/990 [==============================] - 0s 384us/step - loss: 0.8364\n",
      "Epoch 63/150\n",
      "990/990 [==============================] - 0s 421us/step - loss: 0.7729\n",
      "Epoch 64/150\n",
      "990/990 [==============================] - 0s 333us/step - loss: 0.7637\n",
      "Epoch 65/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.7587\n",
      "Epoch 66/150\n",
      "990/990 [==============================] - 0s 442us/step - loss: 0.7322\n",
      "Epoch 67/150\n",
      "990/990 [==============================] - 0s 416us/step - loss: 0.7527\n",
      "Epoch 68/150\n",
      "990/990 [==============================] - 0s 353us/step - loss: 0.7289\n",
      "Epoch 69/150\n",
      "990/990 [==============================] - 0s 397us/step - loss: 0.7530\n",
      "Epoch 70/150\n",
      "990/990 [==============================] - 0s 373us/step - loss: 0.7151\n",
      "Epoch 71/150\n",
      "990/990 [==============================] - 0s 393us/step - loss: 0.7367\n",
      "Epoch 72/150\n",
      "990/990 [==============================] - 0s 409us/step - loss: 0.7196\n",
      "Epoch 73/150\n",
      "990/990 [==============================] - 0s 323us/step - loss: 0.7218\n",
      "Epoch 74/150\n",
      "990/990 [==============================] - 0s 442us/step - loss: 0.6981\n",
      "Epoch 75/150\n",
      "990/990 [==============================] - 0s 389us/step - loss: 0.6820\n",
      "Epoch 76/150\n",
      "990/990 [==============================] - 0s 382us/step - loss: 0.6984\n",
      "Epoch 77/150\n",
      "990/990 [==============================] - 0s 397us/step - loss: 0.6732\n",
      "Epoch 78/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.6636\n",
      "Epoch 79/150\n",
      "990/990 [==============================] - 0s 417us/step - loss: 0.6522\n",
      "Epoch 80/150\n",
      "990/990 [==============================] - 0s 396us/step - loss: 0.6503\n",
      "Epoch 81/150\n",
      "990/990 [==============================] - 0s 394us/step - loss: 0.6502\n",
      "Epoch 82/150\n",
      "990/990 [==============================] - 0s 418us/step - loss: 0.6692\n",
      "Epoch 83/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.6599\n",
      "Epoch 84/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.6497\n",
      "Epoch 85/150\n",
      "990/990 [==============================] - 0s 340us/step - loss: 0.6535\n",
      "Epoch 86/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.6249\n",
      "Epoch 87/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.6155\n",
      "Epoch 88/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.5958\n",
      "Epoch 89/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.6377\n",
      "Epoch 90/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.6079\n",
      "Epoch 91/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.6206\n",
      "Epoch 92/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.5692\n",
      "Epoch 93/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.5960\n",
      "Epoch 94/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.5872\n",
      "Epoch 95/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.5933\n",
      "Epoch 96/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.5753\n",
      "Epoch 97/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.5560\n",
      "Epoch 98/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.5537\n",
      "Epoch 99/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.5492\n",
      "Epoch 100/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.5723\n",
      "Epoch 101/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.5534\n",
      "Epoch 102/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.5302\n",
      "Epoch 103/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.5608\n",
      "Epoch 104/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.5151\n",
      "Epoch 105/150\n",
      "990/990 [==============================] - 0s 326us/step - loss: 0.5477\n",
      "Epoch 106/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.5147\n",
      "Epoch 107/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.5423\n",
      "Epoch 108/150\n",
      "990/990 [==============================] - 0s 327us/step - loss: 0.5346\n",
      "Epoch 109/150\n",
      "990/990 [==============================] - 0s 324us/step - loss: 0.5335\n",
      "Epoch 110/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.5142\n",
      "Epoch 111/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.5060\n",
      "Epoch 112/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.5232\n",
      "Epoch 113/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.5167\n",
      "Epoch 114/150\n",
      "990/990 [==============================] - 0s 316us/step - loss: 0.4742\n",
      "Epoch 115/150\n",
      "990/990 [==============================] - 0s 327us/step - loss: 0.5029\n",
      "Epoch 116/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.4640\n",
      "Epoch 117/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.4906\n",
      "Epoch 118/150\n",
      "990/990 [==============================] - 0s 327us/step - loss: 0.4970\n",
      "Epoch 119/150\n",
      "990/990 [==============================] - 0s 317us/step - loss: 0.4675\n",
      "Epoch 120/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.4877\n",
      "Epoch 121/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.4784\n",
      "Epoch 122/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.4854\n",
      "Epoch 123/150\n",
      "990/990 [==============================] - 0s 321us/step - loss: 0.4855\n",
      "Epoch 124/150\n",
      "990/990 [==============================] - 0s 315us/step - loss: 0.4933\n",
      "Epoch 125/150\n",
      "990/990 [==============================] - 0s 347us/step - loss: 0.4631\n",
      "Epoch 126/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.4910\n",
      "Epoch 127/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.4726\n",
      "Epoch 128/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.4708\n",
      "Epoch 129/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.4485\n",
      "Epoch 130/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.4623\n",
      "Epoch 131/150\n",
      "990/990 [==============================] - 0s 320us/step - loss: 0.4483\n",
      "Epoch 132/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.4504\n",
      "Epoch 133/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.4469\n",
      "Epoch 134/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.4921\n",
      "Epoch 135/150\n",
      "990/990 [==============================] - 0s 319us/step - loss: 0.4332\n",
      "Epoch 136/150\n",
      "990/990 [==============================] - 0s 311us/step - loss: 0.4038\n",
      "Epoch 137/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.4166\n",
      "Epoch 138/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.4425\n",
      "Epoch 139/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.4211\n",
      "Epoch 140/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.4145\n",
      "Epoch 141/150\n",
      "990/990 [==============================] - 0s 322us/step - loss: 0.4289\n",
      "Epoch 142/150\n",
      "990/990 [==============================] - 0s 329us/step - loss: 0.4169\n",
      "Epoch 143/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.4147\n",
      "Epoch 144/150\n",
      "990/990 [==============================] - 0s 312us/step - loss: 0.4139\n",
      "Epoch 145/150\n",
      "990/990 [==============================] - 0s 325us/step - loss: 0.4019\n",
      "Epoch 146/150\n",
      "990/990 [==============================] - 0s 309us/step - loss: 0.4309\n",
      "Epoch 147/150\n",
      "990/990 [==============================] - 0s 314us/step - loss: 0.3994\n",
      "Epoch 148/150\n",
      "990/990 [==============================] - 0s 318us/step - loss: 0.4083\n",
      "Epoch 149/150\n",
      "990/990 [==============================] - 0s 310us/step - loss: 0.3917\n",
      "Epoch 150/150\n",
      "990/990 [==============================] - 0s 313us/step - loss: 0.3930\n",
      "Epoch 1/150\n",
      "990/990 [==============================] - 2s 2ms/step - loss: 4.5781\n",
      "Epoch 2/150\n",
      "990/990 [==============================] - 0s 355us/step - loss: 4.3450\n",
      "Epoch 3/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 3.6475\n",
      "Epoch 4/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 2.9407\n",
      "Epoch 5/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 2.4796\n",
      "Epoch 6/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 2.1473\n",
      "Epoch 7/150\n",
      "990/990 [==============================] - 0s 343us/step - loss: 1.8956\n",
      "Epoch 8/150\n",
      "990/990 [==============================] - 0s 356us/step - loss: 1.6995\n",
      "Epoch 9/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 1.5573\n",
      "Epoch 10/150\n",
      "990/990 [==============================] - 0s 476us/step - loss: 1.3871\n",
      "Epoch 11/150\n",
      "990/990 [==============================] - 0s 362us/step - loss: 1.3077\n",
      "Epoch 12/150\n",
      "990/990 [==============================] - 0s 456us/step - loss: 1.1996\n",
      "Epoch 13/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 1.1329\n",
      "Epoch 14/150\n",
      "990/990 [==============================] - 0s 417us/step - loss: 1.0582\n",
      "Epoch 15/150\n",
      "990/990 [==============================] - 0s 426us/step - loss: 1.0009\n",
      "Epoch 16/150\n",
      "990/990 [==============================] - 0s 404us/step - loss: 0.9404\n",
      "Epoch 17/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.8928\n",
      "Epoch 18/150\n",
      "990/990 [==============================] - 0s 375us/step - loss: 0.8609\n",
      "Epoch 19/150\n",
      "990/990 [==============================] - 0s 347us/step - loss: 0.8140\n",
      "Epoch 20/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.7687\n",
      "Epoch 21/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.7190\n",
      "Epoch 22/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.6785\n",
      "Epoch 23/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.6826\n",
      "Epoch 24/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.6343\n",
      "Epoch 25/150\n",
      "990/990 [==============================] - 0s 353us/step - loss: 0.6224\n",
      "Epoch 26/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 0.5686\n",
      "Epoch 27/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.5743\n",
      "Epoch 28/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.5313\n",
      "Epoch 29/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.5083\n",
      "Epoch 30/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.4704\n",
      "Epoch 31/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.5030\n",
      "Epoch 32/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.4523\n",
      "Epoch 33/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.4475\n",
      "Epoch 34/150\n",
      "990/990 [==============================] - 0s 356us/step - loss: 0.4361\n",
      "Epoch 35/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.4188\n",
      "Epoch 36/150\n",
      "990/990 [==============================] - 0s 360us/step - loss: 0.4005\n",
      "Epoch 37/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.3791\n",
      "Epoch 38/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.3609\n",
      "Epoch 39/150\n",
      "990/990 [==============================] - 0s 362us/step - loss: 0.3593\n",
      "Epoch 40/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.3447\n",
      "Epoch 41/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.3103\n",
      "Epoch 42/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.3404\n",
      "Epoch 43/150\n",
      "990/990 [==============================] - 0s 356us/step - loss: 0.3105\n",
      "Epoch 44/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.3033\n",
      "Epoch 45/150\n",
      "990/990 [==============================] - 0s 376us/step - loss: 0.2760\n",
      "Epoch 46/150\n",
      "990/990 [==============================] - 0s 347us/step - loss: 0.2537\n",
      "Epoch 47/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.2721\n",
      "Epoch 48/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.2476\n",
      "Epoch 49/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.2584\n",
      "Epoch 50/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.2657\n",
      "Epoch 51/150\n",
      "990/990 [==============================] - 0s 365us/step - loss: 0.2465\n",
      "Epoch 52/150\n",
      "990/990 [==============================] - 0s 361us/step - loss: 0.2450\n",
      "Epoch 53/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.2086\n",
      "Epoch 54/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.2215\n",
      "Epoch 55/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.1978\n",
      "Epoch 56/150\n",
      "990/990 [==============================] - 0s 364us/step - loss: 0.1852\n",
      "Epoch 57/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.1806\n",
      "Epoch 58/150\n",
      "990/990 [==============================] - 0s 352us/step - loss: 0.2007\n",
      "Epoch 59/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.1856\n",
      "Epoch 60/150\n",
      "990/990 [==============================] - 0s 363us/step - loss: 0.1790\n",
      "Epoch 61/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.1815\n",
      "Epoch 62/150\n",
      "990/990 [==============================] - 0s 347us/step - loss: 0.1893\n",
      "Epoch 63/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.1750\n",
      "Epoch 64/150\n",
      "990/990 [==============================] - 0s 352us/step - loss: 0.1627\n",
      "Epoch 65/150\n",
      "990/990 [==============================] - 0s 353us/step - loss: 0.1590\n",
      "Epoch 66/150\n",
      "990/990 [==============================] - 0s 363us/step - loss: 0.1699\n",
      "Epoch 67/150\n",
      "990/990 [==============================] - 0s 355us/step - loss: 0.1719\n",
      "Epoch 68/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.1536\n",
      "Epoch 69/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.1484\n",
      "Epoch 70/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.1393\n",
      "Epoch 71/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 0.1423\n",
      "Epoch 72/150\n",
      "990/990 [==============================] - 0s 366us/step - loss: 0.1251\n",
      "Epoch 73/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 0s 347us/step - loss: 0.1239\n",
      "Epoch 74/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 0.1372\n",
      "Epoch 75/150\n",
      "990/990 [==============================] - 0s 366us/step - loss: 0.1290\n",
      "Epoch 76/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.1152\n",
      "Epoch 77/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.1107\n",
      "Epoch 78/150\n",
      "990/990 [==============================] - 0s 356us/step - loss: 0.1060\n",
      "Epoch 79/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.1004\n",
      "Epoch 80/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.1001\n",
      "Epoch 81/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.0890\n",
      "Epoch 82/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.0904\n",
      "Epoch 83/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.1044\n",
      "Epoch 84/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.0958\n",
      "Epoch 85/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 0.0806\n",
      "Epoch 86/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.1018\n",
      "Epoch 87/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.0917\n",
      "Epoch 88/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.0797\n",
      "Epoch 89/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 0.0796\n",
      "Epoch 90/150\n",
      "990/990 [==============================] - 0s 357us/step - loss: 0.0972\n",
      "Epoch 91/150\n",
      "990/990 [==============================] - 0s 345us/step - loss: 0.0993\n",
      "Epoch 92/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.0753\n",
      "Epoch 93/150\n",
      "990/990 [==============================] - 0s 355us/step - loss: 0.0852\n",
      "Epoch 94/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.0762\n",
      "Epoch 95/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.0793\n",
      "Epoch 96/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.0800\n",
      "Epoch 97/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.0808\n",
      "Epoch 98/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.0737\n",
      "Epoch 99/150\n",
      "990/990 [==============================] - 0s 360us/step - loss: 0.0631\n",
      "Epoch 100/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.0644\n",
      "Epoch 101/150\n",
      "990/990 [==============================] - 0s 348us/step - loss: 0.0630\n",
      "Epoch 102/150\n",
      "990/990 [==============================] - 0s 356us/step - loss: 0.0706\n",
      "Epoch 103/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 0.0658\n",
      "Epoch 104/150\n",
      "990/990 [==============================] - 0s 352us/step - loss: 0.0643\n",
      "Epoch 105/150\n",
      "990/990 [==============================] - 0s 367us/step - loss: 0.0528\n",
      "Epoch 106/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 0.0551\n",
      "Epoch 107/150\n",
      "990/990 [==============================] - 0s 349us/step - loss: 0.0606\n",
      "Epoch 108/150\n",
      "990/990 [==============================] - 0s 359us/step - loss: 0.0662\n",
      "Epoch 109/150\n",
      "990/990 [==============================] - 0s 346us/step - loss: 0.0628\n",
      "Epoch 110/150\n",
      "990/990 [==============================] - 0s 351us/step - loss: 0.0650\n",
      "Epoch 111/150\n",
      "990/990 [==============================] - 0s 362us/step - loss: 0.0482\n",
      "Epoch 112/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.0657\n",
      "Epoch 113/150\n",
      "990/990 [==============================] - 0s 344us/step - loss: 0.0614\n",
      "Epoch 114/150\n",
      "990/990 [==============================] - 0s 358us/step - loss: 0.0467\n",
      "Epoch 115/150\n",
      "990/990 [==============================] - 0s 468us/step - loss: 0.0628\n",
      "Epoch 116/150\n",
      "990/990 [==============================] - 0s 480us/step - loss: 0.0483\n",
      "Epoch 117/150\n",
      "990/990 [==============================] - 0s 393us/step - loss: 0.0700\n",
      "Epoch 118/150\n",
      "990/990 [==============================] - 0s 450us/step - loss: 0.0663\n",
      "Epoch 119/150\n",
      "990/990 [==============================] - 0s 459us/step - loss: 0.0606\n",
      "Epoch 120/150\n",
      "990/990 [==============================] - 0s 377us/step - loss: 0.0457\n",
      "Epoch 121/150\n",
      "990/990 [==============================] - 0s 423us/step - loss: 0.0354\n",
      "Epoch 122/150\n",
      "990/990 [==============================] - 0s 444us/step - loss: 0.0493\n",
      "Epoch 123/150\n",
      "990/990 [==============================] - 0s 422us/step - loss: 0.0508\n",
      "Epoch 124/150\n",
      "990/990 [==============================] - 0s 474us/step - loss: 0.0415\n",
      "Epoch 125/150\n",
      "990/990 [==============================] - 0s 350us/step - loss: 0.0377\n",
      "Epoch 126/150\n",
      "990/990 [==============================] - 0s 428us/step - loss: 0.0492\n",
      "Epoch 127/150\n",
      "990/990 [==============================] - 0s 419us/step - loss: 0.0589\n",
      "Epoch 128/150\n",
      "990/990 [==============================] - 0s 444us/step - loss: 0.0576\n",
      "Epoch 129/150\n",
      "990/990 [==============================] - 0s 456us/step - loss: 0.0436\n",
      "Epoch 130/150\n",
      "990/990 [==============================] - 0s 431us/step - loss: 0.0370\n",
      "Epoch 131/150\n",
      "990/990 [==============================] - 0s 454us/step - loss: 0.0374\n",
      "Epoch 132/150\n",
      "990/990 [==============================] - 0s 479us/step - loss: 0.0503\n",
      "Epoch 133/150\n",
      "990/990 [==============================] - 0s 442us/step - loss: 0.0464\n",
      "Epoch 134/150\n",
      "990/990 [==============================] - 0s 459us/step - loss: 0.0506\n",
      "Epoch 135/150\n",
      "990/990 [==============================] - 0s 443us/step - loss: 0.0319\n",
      "Epoch 136/150\n",
      "990/990 [==============================] - 0s 442us/step - loss: 0.0450\n",
      "Epoch 137/150\n",
      "990/990 [==============================] - 0s 381us/step - loss: 0.0395\n",
      "Epoch 138/150\n",
      "990/990 [==============================] - 0s 481us/step - loss: 0.0384\n",
      "Epoch 139/150\n",
      "990/990 [==============================] - 0s 354us/step - loss: 0.0401\n",
      "Epoch 140/150\n",
      "990/990 [==============================] - 0s 431us/step - loss: 0.0312\n",
      "Epoch 141/150\n",
      "990/990 [==============================] - 0s 431us/step - loss: 0.0285\n",
      "Epoch 142/150\n",
      "990/990 [==============================] - 0s 479us/step - loss: 0.0280\n",
      "Epoch 143/150\n",
      "990/990 [==============================] - 0s 449us/step - loss: 0.0316\n",
      "Epoch 144/150\n",
      "990/990 [==============================] - 0s 434us/step - loss: 0.0442\n",
      "Epoch 145/150\n",
      "990/990 [==============================] - 0s 454us/step - loss: 0.0466\n",
      "Epoch 146/150\n",
      "990/990 [==============================] - 0s 428us/step - loss: 0.0403\n",
      "Epoch 147/150\n",
      "990/990 [==============================] - 0s 423us/step - loss: 0.0386\n",
      "Epoch 148/150\n",
      "990/990 [==============================] - 0s 379us/step - loss: 0.0343\n",
      "Epoch 149/150\n",
      "990/990 [==============================] - 0s 412us/step - loss: 0.0362\n",
      "Epoch 150/150\n",
      "990/990 [==============================] - 0s 438us/step - loss: 0.0395\n"
     ]
    }
   ],
   "source": [
    "deep_alex.fit(probs_cnn_train,Y_labels,batch_size=16,epochs=150)\n",
    "deep_shape.fit(train_shape_data,Y_labels,batch_size=16,epochs=150)\n",
    "deep_texture.fit(train_texture_data,Y_labels,batch_size=16,epochs=150)\n",
    "deep_margin.fit(train_margin_data,Y_labels,batch_size=16,epochs=150)\n",
    "deep_sift.fit(vocab_train,Y_labels,batch_size=16,epochs=150)\n",
    "\n",
    "\n",
    "deep_input = np.array(deep_shape.predict(train_shape_data))\n",
    "deep_input = np.array(np.append(deep_input, deep_texture.predict(train_texture_data), axis=1))\n",
    "deep_input = np.array(np.append(deep_input, deep_margin.predict(train_margin_data), axis=1))\n",
    "deep_input = np.array(np.append(deep_input, deep_sift.predict(vocab_train), axis=1))\n",
    "deep_input = np.array(np.append(deep_input, deep_alex.predict(probs_cnn_train), axis=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# deep_final.fit(deep_input,Y_labels,batch_size=16,epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train, and Test the Strong Learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_model = Sequential([\n",
    "#     Dense(512, activation='relu'),\n",
    "#     Dense(1024, activation='relu'),\n",
    "#     Dropout(0.4),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(99, activation='softmax')\n",
    "# ])\n",
    "\n",
    "deep_model = Sequential([\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(99, activation='softmax')\n",
    "])\n",
    "\n",
    "deep_model.compile(loss='categorical_crossentropy',optimizer='adam',metric=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 512)               253952    \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 99)                50787     \n",
      "=================================================================\n",
      "Total params: 567,395\n",
      "Trainable params: 567,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 512)               253952    \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 99)                50787     \n",
      "=================================================================\n",
      "Total params: 567,395\n",
      "Trainable params: 567,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# deep_input=np.array(np.append(train_margin_data,train_texture_data,axis=1))\n",
    "# deep_input=np.array(np.append(deep_input,train_shape_data,axis=1))\n",
    "# deep_input=np.array(np.append(deep_input,vocab_train,axis=1))\n",
    "# deep_input=np.array(np.append(deep_input,probs_cnn_train,axis=1))\n",
    "# Y_labels = np_utils.to_categorical(train_labels_encoded,99)\n",
    "# print deep_input.shape\n",
    "deep_model.summary()\n",
    "deep_model.layers.pop()\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/200\n",
      "792/792 [==============================] - 3s 4ms/step - loss: 4.1966 - val_loss: 3.5697\n",
      "Epoch 2/200\n",
      "792/792 [==============================] - 0s 631us/step - loss: 2.3057 - val_loss: 1.2145\n",
      "Epoch 3/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 0.2929 - val_loss: 0.0786\n",
      "Epoch 4/200\n",
      "792/792 [==============================] - 0s 615us/step - loss: 0.0246 - val_loss: 0.0143\n",
      "Epoch 5/200\n",
      "792/792 [==============================] - 0s 580us/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 6/200\n",
      "792/792 [==============================] - 0s 582us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 7/200\n",
      "792/792 [==============================] - 0s 613us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 8/200\n",
      "792/792 [==============================] - 0s 580us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 9/200\n",
      "792/792 [==============================] - 0s 596us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/200\n",
      "792/792 [==============================] - 0s 581us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 11/200\n",
      "792/792 [==============================] - 0s 601us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 12/200\n",
      "792/792 [==============================] - 0s 589us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 13/200\n",
      "792/792 [==============================] - 0s 605us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 14/200\n",
      "792/792 [==============================] - 0s 591us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/200\n",
      "792/792 [==============================] - 0s 605us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 16/200\n",
      "792/792 [==============================] - 0s 589us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 17/200\n",
      "792/792 [==============================] - 0s 586us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "792/792 [==============================] - 0s 599us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "792/792 [==============================] - 0s 591us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 0.0010 - val_loss: 9.8898e-04\n",
      "Epoch 21/200\n",
      "792/792 [==============================] - 0s 589us/step - loss: 8.7309e-04 - val_loss: 9.1384e-04\n",
      "Epoch 22/200\n",
      "792/792 [==============================] - 0s 601us/step - loss: 8.1482e-04 - val_loss: 8.3916e-04\n",
      "Epoch 23/200\n",
      "792/792 [==============================] - 0s 581us/step - loss: 8.1636e-04 - val_loss: 7.7772e-04\n",
      "Epoch 24/200\n",
      "792/792 [==============================] - 0s 596us/step - loss: 7.4490e-04 - val_loss: 7.2278e-04\n",
      "Epoch 25/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 7.0207e-04 - val_loss: 6.7491e-04\n",
      "Epoch 26/200\n",
      "792/792 [==============================] - 1s 632us/step - loss: 6.4842e-04 - val_loss: 6.2685e-04\n",
      "Epoch 27/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 6.1556e-04 - val_loss: 5.8380e-04\n",
      "Epoch 28/200\n",
      "792/792 [==============================] - 0s 582us/step - loss: 5.4776e-04 - val_loss: 5.5130e-04\n",
      "Epoch 29/200\n",
      "792/792 [==============================] - 0s 601us/step - loss: 5.3631e-04 - val_loss: 5.1799e-04\n",
      "Epoch 30/200\n",
      "792/792 [==============================] - 0s 582us/step - loss: 5.1290e-04 - val_loss: 4.8662e-04\n",
      "Epoch 31/200\n",
      "792/792 [==============================] - 0s 597us/step - loss: 4.7550e-04 - val_loss: 4.5658e-04\n",
      "Epoch 32/200\n",
      "792/792 [==============================] - 0s 586us/step - loss: 4.5005e-04 - val_loss: 4.3059e-04\n",
      "Epoch 33/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 4.3539e-04 - val_loss: 4.0827e-04\n",
      "Epoch 34/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 4.2865e-04 - val_loss: 3.8121e-04\n",
      "Epoch 35/200\n",
      "792/792 [==============================] - 0s 604us/step - loss: 3.7668e-04 - val_loss: 3.6145e-04\n",
      "Epoch 36/200\n",
      "792/792 [==============================] - 0s 585us/step - loss: 3.6777e-04 - val_loss: 3.4359e-04\n",
      "Epoch 37/200\n",
      "792/792 [==============================] - 0s 591us/step - loss: 3.5824e-04 - val_loss: 3.2417e-04\n",
      "Epoch 38/200\n",
      "792/792 [==============================] - 0s 599us/step - loss: 3.2530e-04 - val_loss: 3.0709e-04\n",
      "Epoch 39/200\n",
      "792/792 [==============================] - 0s 583us/step - loss: 3.2594e-04 - val_loss: 2.9226e-04\n",
      "Epoch 40/200\n",
      "792/792 [==============================] - 0s 603us/step - loss: 3.0270e-04 - val_loss: 2.7786e-04\n",
      "Epoch 41/200\n",
      "792/792 [==============================] - 0s 588us/step - loss: 2.8567e-04 - val_loss: 2.6520e-04\n",
      "Epoch 42/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 2.8632e-04 - val_loss: 2.5223e-04\n",
      "Epoch 43/200\n",
      "792/792 [==============================] - 0s 586us/step - loss: 2.4445e-04 - val_loss: 2.4166e-04\n",
      "Epoch 44/200\n",
      "792/792 [==============================] - 0s 595us/step - loss: 2.5189e-04 - val_loss: 2.3214e-04\n",
      "Epoch 45/200\n",
      "792/792 [==============================] - 0s 586us/step - loss: 2.4198e-04 - val_loss: 2.2260e-04\n",
      "Epoch 46/200\n",
      "792/792 [==============================] - 0s 598us/step - loss: 2.3137e-04 - val_loss: 2.1376e-04\n",
      "Epoch 47/200\n",
      "792/792 [==============================] - 0s 591us/step - loss: 2.1860e-04 - val_loss: 2.0455e-04\n",
      "Epoch 48/200\n",
      "792/792 [==============================] - 0s 606us/step - loss: 2.1598e-04 - val_loss: 1.9717e-04\n",
      "Epoch 49/200\n",
      "792/792 [==============================] - 1s 737us/step - loss: 2.1633e-04 - val_loss: 1.8885e-04\n",
      "Epoch 50/200\n",
      "792/792 [==============================] - 1s 693us/step - loss: 2.0553e-04 - val_loss: 1.8072e-04\n",
      "Epoch 51/200\n",
      "792/792 [==============================] - 1s 705us/step - loss: 1.8717e-04 - val_loss: 1.7403e-04\n",
      "Epoch 52/200\n",
      "792/792 [==============================] - 1s 706us/step - loss: 1.8255e-04 - val_loss: 1.6757e-04\n",
      "Epoch 53/200\n",
      "792/792 [==============================] - 1s 663us/step - loss: 1.7696e-04 - val_loss: 1.6156e-04\n",
      "Epoch 54/200\n",
      "792/792 [==============================] - 1s 651us/step - loss: 1.7043e-04 - val_loss: 1.5573e-04\n",
      "Epoch 55/200\n",
      "792/792 [==============================] - 1s 720us/step - loss: 1.7136e-04 - val_loss: 1.5028e-04\n",
      "Epoch 56/200\n",
      "792/792 [==============================] - 1s 692us/step - loss: 1.6035e-04 - val_loss: 1.4478e-04\n",
      "Epoch 57/200\n",
      "792/792 [==============================] - 1s 735us/step - loss: 1.4979e-04 - val_loss: 1.4003e-04\n",
      "Epoch 58/200\n",
      "792/792 [==============================] - 1s 654us/step - loss: 1.3715e-04 - val_loss: 1.3570e-04\n",
      "Epoch 59/200\n",
      "792/792 [==============================] - 1s 675us/step - loss: 1.4254e-04 - val_loss: 1.3145e-04\n",
      "Epoch 60/200\n",
      "792/792 [==============================] - 1s 727us/step - loss: 1.3866e-04 - val_loss: 1.2693e-04\n",
      "Epoch 61/200\n",
      "792/792 [==============================] - 1s 638us/step - loss: 1.4236e-04 - val_loss: 1.2252e-04\n",
      "Epoch 62/200\n",
      "792/792 [==============================] - 1s 753us/step - loss: 1.3680e-04 - val_loss: 1.1806e-04\n",
      "Epoch 63/200\n",
      "792/792 [==============================] - 1s 782us/step - loss: 1.3026e-04 - val_loss: 1.1374e-04\n",
      "Epoch 64/200\n",
      "792/792 [==============================] - 1s 706us/step - loss: 1.2094e-04 - val_loss: 1.1001e-04\n",
      "Epoch 65/200\n",
      "792/792 [==============================] - 1s 737us/step - loss: 1.1866e-04 - val_loss: 1.0663e-04\n",
      "Epoch 66/200\n",
      "792/792 [==============================] - 1s 774us/step - loss: 1.1188e-04 - val_loss: 1.0332e-04\n",
      "Epoch 67/200\n",
      "792/792 [==============================] - 1s 719us/step - loss: 1.1401e-04 - val_loss: 1.0028e-04\n",
      "Epoch 68/200\n",
      "792/792 [==============================] - 0s 625us/step - loss: 1.1289e-04 - val_loss: 9.7158e-05\n",
      "Epoch 69/200\n",
      "792/792 [==============================] - 0s 617us/step - loss: 1.0036e-04 - val_loss: 9.4168e-05\n",
      "Epoch 70/200\n",
      "792/792 [==============================] - 0s 616us/step - loss: 1.0511e-04 - val_loss: 9.1361e-05\n",
      "Epoch 71/200\n",
      "792/792 [==============================] - 0s 611us/step - loss: 9.5164e-05 - val_loss: 8.8798e-05\n",
      "Epoch 72/200\n",
      "792/792 [==============================] - 0s 625us/step - loss: 1.0262e-04 - val_loss: 8.5969e-05\n",
      "Epoch 73/200\n",
      "792/792 [==============================] - 0s 611us/step - loss: 9.4925e-05 - val_loss: 8.3411e-05\n",
      "Epoch 74/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 8.7982e-05 - val_loss: 8.1004e-05\n",
      "Epoch 75/200\n",
      "792/792 [==============================] - 0s 583us/step - loss: 8.2967e-05 - val_loss: 7.8758e-05\n",
      "Epoch 76/200\n",
      "792/792 [==============================] - 0s 587us/step - loss: 8.2621e-05 - val_loss: 7.6860e-05\n",
      "Epoch 77/200\n",
      "792/792 [==============================] - 0s 576us/step - loss: 8.4349e-05 - val_loss: 7.4700e-05\n",
      "Epoch 78/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 8.1985e-05 - val_loss: 7.2575e-05\n",
      "Epoch 79/200\n",
      "792/792 [==============================] - 0s 581us/step - loss: 7.7021e-05 - val_loss: 7.0603e-05\n",
      "Epoch 80/200\n",
      "792/792 [==============================] - 0s 586us/step - loss: 7.9189e-05 - val_loss: 6.8680e-05\n",
      "Epoch 81/200\n",
      "792/792 [==============================] - 0s 583us/step - loss: 7.1862e-05 - val_loss: 6.7038e-05\n",
      "Epoch 82/200\n",
      "792/792 [==============================] - 0s 573us/step - loss: 7.4885e-05 - val_loss: 6.5309e-05\n",
      "Epoch 83/200\n",
      "792/792 [==============================] - 0s 593us/step - loss: 7.2972e-05 - val_loss: 6.3483e-05\n",
      "Epoch 84/200\n",
      "792/792 [==============================] - 0s 575us/step - loss: 7.1211e-05 - val_loss: 6.1788e-05\n",
      "Epoch 85/200\n",
      "792/792 [==============================] - 0s 594us/step - loss: 7.3871e-05 - val_loss: 5.9946e-05\n",
      "Epoch 86/200\n",
      "792/792 [==============================] - 0s 578us/step - loss: 6.7434e-05 - val_loss: 5.8270e-05\n",
      "Epoch 87/200\n",
      "792/792 [==============================] - 0s 597us/step - loss: 6.6885e-05 - val_loss: 5.6722e-05\n",
      "Epoch 88/200\n",
      "792/792 [==============================] - 0s 577us/step - loss: 6.4103e-05 - val_loss: 5.5226e-05\n",
      "Epoch 89/200\n",
      "792/792 [==============================] - 0s 587us/step - loss: 5.9278e-05 - val_loss: 5.3925e-05\n",
      "Epoch 90/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 6.1547e-05 - val_loss: 5.2554e-05\n",
      "Epoch 91/200\n",
      "792/792 [==============================] - 0s 577us/step - loss: 5.7486e-05 - val_loss: 5.1363e-05\n",
      "Epoch 92/200\n",
      "792/792 [==============================] - 0s 604us/step - loss: 5.7146e-05 - val_loss: 5.0193e-05\n",
      "Epoch 93/200\n",
      "792/792 [==============================] - 0s 584us/step - loss: 5.6810e-05 - val_loss: 4.9005e-05\n",
      "Epoch 94/200\n",
      "792/792 [==============================] - 1s 657us/step - loss: 5.4230e-05 - val_loss: 4.7888e-05\n",
      "Epoch 95/200\n",
      "792/792 [==============================] - 0s 599us/step - loss: 5.1728e-05 - val_loss: 4.6750e-05\n",
      "Epoch 96/200\n",
      "792/792 [==============================] - 0s 613us/step - loss: 5.0939e-05 - val_loss: 4.5664e-05\n",
      "Epoch 97/200\n",
      "792/792 [==============================] - 0s 595us/step - loss: 4.9841e-05 - val_loss: 4.4643e-05\n",
      "Epoch 98/200\n",
      "792/792 [==============================] - 0s 606us/step - loss: 5.0673e-05 - val_loss: 4.3601e-05\n",
      "Epoch 99/200\n",
      "792/792 [==============================] - 0s 602us/step - loss: 4.9564e-05 - val_loss: 4.2482e-05\n",
      "Epoch 100/200\n",
      "792/792 [==============================] - 0s 589us/step - loss: 4.7404e-05 - val_loss: 4.1449e-05\n",
      "Epoch 101/200\n",
      "792/792 [==============================] - 0s 579us/step - loss: 4.8461e-05 - val_loss: 4.0495e-05\n",
      "Epoch 102/200\n",
      "792/792 [==============================] - 0s 579us/step - loss: 4.8489e-05 - val_loss: 3.9512e-05\n",
      "Epoch 103/200\n",
      "792/792 [==============================] - 0s 594us/step - loss: 4.5649e-05 - val_loss: 3.8455e-05\n",
      "Epoch 104/200\n",
      "792/792 [==============================] - 0s 574us/step - loss: 4.2659e-05 - val_loss: 3.7690e-05\n",
      "Epoch 105/200\n",
      "792/792 [==============================] - 0s 589us/step - loss: 4.2876e-05 - val_loss: 3.6824e-05\n",
      "Epoch 106/200\n",
      "792/792 [==============================] - 0s 575us/step - loss: 4.2487e-05 - val_loss: 3.6044e-05\n",
      "Epoch 107/200\n",
      "792/792 [==============================] - 0s 592us/step - loss: 4.3978e-05 - val_loss: 3.5318e-05\n",
      "Epoch 108/200\n",
      "792/792 [==============================] - 0s 585us/step - loss: 4.1439e-05 - val_loss: 3.4561e-05\n",
      "Epoch 109/200\n",
      "792/792 [==============================] - 1s 675us/step - loss: 4.4058e-05 - val_loss: 3.3668e-05\n",
      "Epoch 110/200\n",
      "792/792 [==============================] - 1s 747us/step - loss: 3.7548e-05 - val_loss: 3.2892e-05\n",
      "Epoch 111/200\n",
      "792/792 [==============================] - 1s 732us/step - loss: 4.0422e-05 - val_loss: 3.2190e-05\n",
      "Epoch 112/200\n",
      "792/792 [==============================] - 1s 686us/step - loss: 3.7777e-05 - val_loss: 3.1463e-05\n",
      "Epoch 113/200\n",
      "792/792 [==============================] - 1s 815us/step - loss: 3.6280e-05 - val_loss: 3.0780e-05\n",
      "Epoch 114/200\n",
      "792/792 [==============================] - 1s 781us/step - loss: 3.7781e-05 - val_loss: 3.0160e-05\n",
      "Epoch 115/200\n",
      "792/792 [==============================] - 1s 764us/step - loss: 3.2928e-05 - val_loss: 2.9540e-05\n",
      "Epoch 116/200\n",
      "792/792 [==============================] - 1s 766us/step - loss: 3.3737e-05 - val_loss: 2.8940e-05\n",
      "Epoch 117/200\n",
      "792/792 [==============================] - 1s 707us/step - loss: 3.6242e-05 - val_loss: 2.8293e-05\n",
      "Epoch 118/200\n",
      "792/792 [==============================] - 1s 711us/step - loss: 3.3664e-05 - val_loss: 2.7701e-05\n",
      "Epoch 119/200\n",
      "792/792 [==============================] - 1s 695us/step - loss: 3.5289e-05 - val_loss: 2.7115e-05\n",
      "Epoch 120/200\n",
      "792/792 [==============================] - 1s 739us/step - loss: 3.3655e-05 - val_loss: 2.6527e-05\n",
      "Epoch 121/200\n",
      "792/792 [==============================] - 1s 684us/step - loss: 2.9054e-05 - val_loss: 2.5871e-05\n",
      "Epoch 122/200\n",
      "792/792 [==============================] - 1s 644us/step - loss: 3.1484e-05 - val_loss: 2.5273e-05\n",
      "Epoch 123/200\n",
      "792/792 [==============================] - 0s 624us/step - loss: 2.9293e-05 - val_loss: 2.4739e-05\n",
      "Epoch 124/200\n",
      "792/792 [==============================] - 1s 738us/step - loss: 3.0780e-05 - val_loss: 2.4280e-05\n",
      "Epoch 125/200\n",
      "792/792 [==============================] - 1s 676us/step - loss: 2.6166e-05 - val_loss: 2.3768e-05\n",
      "Epoch 126/200\n",
      "792/792 [==============================] - 1s 722us/step - loss: 2.9155e-05 - val_loss: 2.3352e-05\n",
      "Epoch 127/200\n",
      "792/792 [==============================] - 0s 617us/step - loss: 2.8242e-05 - val_loss: 2.2798e-05\n",
      "Epoch 128/200\n",
      "792/792 [==============================] - 0s 627us/step - loss: 2.8207e-05 - val_loss: 2.2299e-05\n",
      "Epoch 129/200\n",
      "792/792 [==============================] - 0s 606us/step - loss: 2.5786e-05 - val_loss: 2.1840e-05\n",
      "Epoch 130/200\n",
      "792/792 [==============================] - 1s 636us/step - loss: 2.4684e-05 - val_loss: 2.1451e-05\n",
      "Epoch 131/200\n",
      "792/792 [==============================] - 0s 604us/step - loss: 2.5344e-05 - val_loss: 2.0993e-05\n",
      "Epoch 132/200\n",
      "792/792 [==============================] - 0s 614us/step - loss: 2.4489e-05 - val_loss: 2.0578e-05\n",
      "Epoch 133/200\n",
      "792/792 [==============================] - 0s 612us/step - loss: 2.6205e-05 - val_loss: 2.0168e-05\n",
      "Epoch 134/200\n",
      "792/792 [==============================] - 0s 599us/step - loss: 2.4552e-05 - val_loss: 1.9764e-05\n",
      "Epoch 135/200\n",
      "792/792 [==============================] - 0s 590us/step - loss: 2.2758e-05 - val_loss: 1.9448e-05\n",
      "Epoch 136/200\n",
      "792/792 [==============================] - 1s 633us/step - loss: 2.4250e-05 - val_loss: 1.9037e-05\n",
      "Epoch 137/200\n",
      "792/792 [==============================] - 1s 885us/step - loss: 2.1144e-05 - val_loss: 1.8670e-05\n",
      "Epoch 138/200\n",
      "792/792 [==============================] - 1s 720us/step - loss: 2.3025e-05 - val_loss: 1.8351e-05\n",
      "Epoch 139/200\n",
      "792/792 [==============================] - 1s 710us/step - loss: 2.1589e-05 - val_loss: 1.7980e-05\n",
      "Epoch 140/200\n",
      "792/792 [==============================] - 1s 743us/step - loss: 2.2238e-05 - val_loss: 1.7619e-05\n",
      "Epoch 141/200\n",
      "792/792 [==============================] - 1s 740us/step - loss: 2.1844e-05 - val_loss: 1.7285e-05\n",
      "Epoch 142/200\n",
      "792/792 [==============================] - 1s 725us/step - loss: 2.1388e-05 - val_loss: 1.6951e-05\n",
      "Epoch 143/200\n",
      "792/792 [==============================] - 1s 683us/step - loss: 1.9917e-05 - val_loss: 1.6628e-05\n",
      "Epoch 144/200\n",
      "792/792 [==============================] - 1s 743us/step - loss: 1.9141e-05 - val_loss: 1.6342e-05\n",
      "Epoch 145/200\n",
      "792/792 [==============================] - 1s 652us/step - loss: 1.9651e-05 - val_loss: 1.6031e-05\n",
      "Epoch 146/200\n",
      "792/792 [==============================] - 1s 734us/step - loss: 1.8925e-05 - val_loss: 1.5739e-05\n",
      "Epoch 147/200\n",
      "792/792 [==============================] - 1s 657us/step - loss: 1.8119e-05 - val_loss: 1.5476e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "792/792 [==============================] - 1s 697us/step - loss: 1.9372e-05 - val_loss: 1.5208e-05\n",
      "Epoch 149/200\n",
      "792/792 [==============================] - 1s 722us/step - loss: 1.7274e-05 - val_loss: 1.4969e-05\n",
      "Epoch 150/200\n",
      "792/792 [==============================] - 1s 676us/step - loss: 1.9074e-05 - val_loss: 1.4727e-05\n",
      "Epoch 151/200\n",
      "792/792 [==============================] - 1s 790us/step - loss: 1.5969e-05 - val_loss: 1.4440e-05\n",
      "Epoch 152/200\n",
      "792/792 [==============================] - 1s 724us/step - loss: 1.7297e-05 - val_loss: 1.4143e-05\n",
      "Epoch 153/200\n",
      "792/792 [==============================] - 1s 701us/step - loss: 1.7070e-05 - val_loss: 1.3866e-05\n",
      "Epoch 154/200\n",
      "792/792 [==============================] - 1s 674us/step - loss: 1.8028e-05 - val_loss: 1.3621e-05\n",
      "Epoch 155/200\n",
      "792/792 [==============================] - 1s 732us/step - loss: 1.6242e-05 - val_loss: 1.3365e-05\n",
      "Epoch 156/200\n",
      "792/792 [==============================] - 1s 662us/step - loss: 1.6186e-05 - val_loss: 1.3126e-05\n",
      "Epoch 157/200\n",
      "792/792 [==============================] - 1s 787us/step - loss: 1.5785e-05 - val_loss: 1.2907e-05\n",
      "Epoch 158/200\n",
      "792/792 [==============================] - 1s 693us/step - loss: 1.5900e-05 - val_loss: 1.2644e-05\n",
      "Epoch 159/200\n",
      "792/792 [==============================] - 1s 730us/step - loss: 1.5655e-05 - val_loss: 1.2375e-05\n",
      "Epoch 160/200\n",
      "792/792 [==============================] - 1s 726us/step - loss: 1.4825e-05 - val_loss: 1.2150e-05\n",
      "Epoch 161/200\n",
      "792/792 [==============================] - 1s 680us/step - loss: 1.5169e-05 - val_loss: 1.1911e-05\n",
      "Epoch 162/200\n",
      "792/792 [==============================] - 1s 703us/step - loss: 1.4329e-05 - val_loss: 1.1705e-05\n",
      "Epoch 163/200\n",
      "792/792 [==============================] - 0s 600us/step - loss: 1.4358e-05 - val_loss: 1.1504e-05\n",
      "Epoch 164/200\n",
      "792/792 [==============================] - 1s 737us/step - loss: 1.4308e-05 - val_loss: 1.1317e-05\n",
      "Epoch 165/200\n",
      "792/792 [==============================] - 1s 670us/step - loss: 1.3895e-05 - val_loss: 1.1096e-05\n",
      "Epoch 166/200\n",
      "792/792 [==============================] - 1s 719us/step - loss: 1.3499e-05 - val_loss: 1.0899e-05\n",
      "Epoch 167/200\n",
      "792/792 [==============================] - 1s 725us/step - loss: 1.3383e-05 - val_loss: 1.0712e-05\n",
      "Epoch 168/200\n",
      "792/792 [==============================] - 1s 682us/step - loss: 1.2934e-05 - val_loss: 1.0471e-05\n",
      "Epoch 169/200\n",
      "792/792 [==============================] - 1s 690us/step - loss: 1.2243e-05 - val_loss: 1.0288e-05\n",
      "Epoch 170/200\n",
      "792/792 [==============================] - 1s 782us/step - loss: 1.3936e-05 - val_loss: 1.0120e-05\n",
      "Epoch 171/200\n",
      "792/792 [==============================] - 1s 662us/step - loss: 1.2190e-05 - val_loss: 9.9794e-06\n",
      "Epoch 172/200\n",
      "792/792 [==============================] - 1s 655us/step - loss: 1.2240e-05 - val_loss: 9.8159e-06\n",
      "Epoch 173/200\n",
      "792/792 [==============================] - 1s 707us/step - loss: 1.2238e-05 - val_loss: 9.6699e-06\n",
      "Epoch 174/200\n",
      "792/792 [==============================] - 1s 688us/step - loss: 1.1685e-05 - val_loss: 9.5164e-06\n",
      "Epoch 175/200\n",
      "792/792 [==============================] - 1s 737us/step - loss: 1.1709e-05 - val_loss: 9.3285e-06\n",
      "Epoch 176/200\n",
      "792/792 [==============================] - 1s 687us/step - loss: 1.1295e-05 - val_loss: 9.1777e-06\n",
      "Epoch 177/200\n",
      "792/792 [==============================] - 1s 837us/step - loss: 1.1291e-05 - val_loss: 9.0287e-06\n",
      "Epoch 178/200\n",
      "792/792 [==============================] - 1s 838us/step - loss: 1.1730e-05 - val_loss: 8.8761e-06\n",
      "Epoch 179/200\n",
      "792/792 [==============================] - 1s 887us/step - loss: 1.1137e-05 - val_loss: 8.7262e-06\n",
      "Epoch 180/200\n",
      "792/792 [==============================] - 1s 822us/step - loss: 1.1013e-05 - val_loss: 8.5720e-06\n",
      "Epoch 181/200\n",
      "792/792 [==============================] - 1s 781us/step - loss: 1.1629e-05 - val_loss: 8.4206e-06\n",
      "Epoch 182/200\n",
      "792/792 [==============================] - 1s 762us/step - loss: 1.0803e-05 - val_loss: 8.2647e-06\n",
      "Epoch 183/200\n",
      "792/792 [==============================] - 1s 713us/step - loss: 1.0120e-05 - val_loss: 8.1217e-06\n",
      "Epoch 184/200\n",
      "792/792 [==============================] - 1s 690us/step - loss: 9.2653e-06 - val_loss: 7.9868e-06\n",
      "Epoch 185/200\n",
      "792/792 [==============================] - 0s 606us/step - loss: 1.0375e-05 - val_loss: 7.8516e-06\n",
      "Epoch 186/200\n",
      "792/792 [==============================] - 1s 764us/step - loss: 1.0319e-05 - val_loss: 7.7327e-06\n",
      "Epoch 187/200\n",
      "792/792 [==============================] - 1s 717us/step - loss: 1.0032e-05 - val_loss: 7.6111e-06\n",
      "Epoch 188/200\n",
      "792/792 [==============================] - 1s 719us/step - loss: 1.0186e-05 - val_loss: 7.4940e-06\n",
      "Epoch 189/200\n",
      "792/792 [==============================] - 1s 682us/step - loss: 9.6385e-06 - val_loss: 7.3832e-06\n",
      "Epoch 190/200\n",
      "792/792 [==============================] - 1s 709us/step - loss: 9.2942e-06 - val_loss: 7.2773e-06\n",
      "Epoch 191/200\n",
      "792/792 [==============================] - 1s 684us/step - loss: 8.9281e-06 - val_loss: 7.1644e-06\n",
      "Epoch 192/200\n",
      "792/792 [==============================] - 0s 622us/step - loss: 9.3592e-06 - val_loss: 7.0337e-06\n",
      "Epoch 193/200\n",
      "792/792 [==============================] - 1s 722us/step - loss: 9.2358e-06 - val_loss: 6.9202e-06\n",
      "Epoch 194/200\n",
      "792/792 [==============================] - 1s 726us/step - loss: 8.7458e-06 - val_loss: 6.7896e-06\n",
      "Epoch 195/200\n",
      "792/792 [==============================] - 1s 687us/step - loss: 8.1800e-06 - val_loss: 6.6764e-06\n",
      "Epoch 196/200\n",
      "792/792 [==============================] - 1s 746us/step - loss: 8.1483e-06 - val_loss: 6.5689e-06\n",
      "Epoch 197/200\n",
      "792/792 [==============================] - 1s 746us/step - loss: 7.8716e-06 - val_loss: 6.4587e-06\n",
      "Epoch 198/200\n",
      "792/792 [==============================] - 1s 677us/step - loss: 8.4486e-06 - val_loss: 6.3513e-06\n",
      "Epoch 199/200\n",
      "792/792 [==============================] - 1s 739us/step - loss: 8.7281e-06 - val_loss: 6.2432e-06\n",
      "Epoch 200/200\n",
      "792/792 [==============================] - 1s 734us/step - loss: 7.7640e-06 - val_loss: 6.1216e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 512)               253952    \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 99)                50787     \n",
      "=================================================================\n",
      "Total params: 567,395\n",
      "Trainable params: 567,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.fit(deep_input,Y_labels,batch_size=32,epochs=200, validation_split=0.2)\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_input = np.array(deep_shape.predict(train_shape_data))\n",
    "# deep_input = np.array(np.append(deep_input, deep_texture.predict(train_texture_data), axis=1))\n",
    "# deep_input = np.array(np.append(deep_input, deep_margin.predict(train_margin_data), axis=1))\n",
    "# deep_input = np.array(np.append(deep_input, deep_sift.predict(vocab_train), axis=1))\n",
    "# deep_input = np.array(np.append(deep_input, deep_alex.predict(probs_cnn_train), axis=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the output for the Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_input_test = np.array(deep_shape.predict(test_shape_data))\n",
    "deep_input_test = np.array(np.append(deep_input_test, deep_texture.predict(test_texture_data), axis=1))\n",
    "deep_input_test = np.array(np.append(deep_input_test, deep_margin.predict(test_margin_data), axis=1))\n",
    "deep_input_test = np.array(np.append(deep_input_test, deep_sift.predict(vocab_test), axis=1))\n",
    "deep_input_test = np.array(np.append(deep_input_test, deep_alex.predict(probs_cnn_test), axis=1))\n",
    "\n",
    "\n",
    "out_file = deep_model.predict(deep_input_test)\n",
    "out_file = np.append(np.array(test_ids).reshape(-1,1),out_file,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishsaha/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# out_file = generateSubmission(test_ids, test_data,svm_model,99)\n",
    "headerRow=np.array(['id'] + le.inverse_transform(range(99)).tolist())\n",
    "df = pd.DataFrame(data=out_file, columns = headerRow)\n",
    "df['id'] = df['id'].astype(np.int)\n",
    "df=df.set_index('id')\n",
    "#print df.head()\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print out_file\n",
    "df.to_csv('output/28_11_18_013(ALexNet15Deep).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
